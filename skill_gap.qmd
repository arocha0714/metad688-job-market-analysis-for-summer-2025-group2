---
title: Skill Gap Analysis
format:
    html:
        toc: true
        toc-depth: 2
execute:
  echo: false   
  warning: false  
  message: false   
  eval: false
---
```{python}
#| results: 'hide'
#| echo: false

import findspark
findspark.init()

from pyspark.sql import SparkSession
import pandas as pd
import plotly.express as px
import plotly.io as pio
import numpy as np

np.random.seed(42)

pio.renderers.default = "notebook"

# Initialize Spark Session
spark = SparkSession.builder.appName("LightcastData").getOrCreate()

# Load Data
df = spark.read.option("header", "true").option("inferSchema", "true").option("multiLine","true").option("escape", "\"").csv("./data/lightcast_job_postings.csv")



```

```{python}
#| echo: false

df.createOrReplaceTempView("jobs")
```

```{python}
#| results: 'hide'
#| echo: false
software_skill_counts_by_type = spark.sql("""
    SELECT software_skills_name, COUNT(*) AS count
    FROM jobs
    WHERE LOWER(title_name) LIKE '%analyst%'
       OR LOWER(title_name) LIKE '%analysis%'
       OR LOWER(title_name) LIKE '%analytics%'
    GROUP BY software_skills_name
    ORDER BY count DESC
    LIMIT 10
""")
software_skill_counts_by_type.show(truncate=False)
```

```{python}
#| results: 'hide'
#| echo: false
skill_counts_by_type = spark.sql("""
    SELECT skills_name, COUNT(*) AS count
    FROM jobs
    WHERE LOWER(title_name) LIKE '%analyst%'
    OR LOWER(title_name) LIKE '%analysis%'
    OR LOWER(title_name) LIKE '%analytics%'
    GROUP BY skills_name
    ORDER BY count DESC
    LIMIT 10
""")
skill_counts_by_type.show(truncate=False)
```

```{python}
#| results: 'hide'
#| echo: false
import pandas as pd

skills_data = {
    "Name": ["Alyssa", "Adam", "Yihan"],
    "Microsoft Office": [4, 5, 3],
    "Dashboard": [3, 3, 1],
    "SQL": [2, 2, 2],
    "OneStream": [1, 1, 1],
    "Cloud Computing": [2, 2, 2]
}

df_skills = pd.DataFrame(skills_data)
df_skills.set_index("Name", inplace=True)
df_skills
```


```{python}
#| eval: false
#| echo: false
#| warning: false
#| fig-cap: "Skillset Analysis"
#| fig-align: center
#| label: fig-analyst-distribution

import pandas as pd
import plotly.graph_objects as go

# Your data
skills_data = {
    "Name": ["Alyssa", "Adam", "Yihan"],
    "Microsoft Office": [4, 5, 3],
    "Dashboard": [3, 3, 1],
    "SQL": [2, 2, 2],
    "OneStream": [0, 0, 0],
    "Cloud Computing": [2, 2, 2]
}

# Create DataFrame
df_skills = pd.DataFrame(skills_data)
df_skills.set_index("Name", inplace=True)

# Get skill categories
categories = df_skills.columns.tolist()

# Create Plotly radar chart
fig = go.Figure()

for name in df_skills.index:
    values = df_skills.loc[name].tolist()
    values += values[:1]  # close the radar loop

    fig.add_trace(go.Scatterpolar(
        r=values,
        theta=categories + [categories[0]],  # close the loop
        fill='toself',
        name=name
    ))

# Customize layout
fig.update_layout(
    polar=dict(
        radialaxis=dict(
            visible=True,
            range=[0, 6]
        )),
    showlegend=True,
    title="Team Skillset Levels"
)
fig.show()


fig.write_html("./figures/skill_gap.html", include_plotlyjs='cdn')

#https://plotly.com/python/radar-chart/
```

```{=html}
<iframe width="1000" height="700" src="./figures/skill_gap.html" title="Market Comparison"></iframe>
```
# Recomendations

Given our analysis above, we have decided to focus on some of the key actions and learning goals that each of us can take in order to further our chances of landing a high quality position in our chosen industry.


### SQL

#### Beginner

We recommend using tools such as SQLBolt to begin developing a foundational understanding of basic syntax, queries, and selecting columns from datasets. This will build familiarity with the program itself and develop a confidence in import and simple manipulation of data.

#### Intermediate

Next, we will incorporate real-world data sets (ex. Kaggle) to begin creating analysis. As an example, you could utilize sales data, new customers, inventory levels, certain trends over time, etc. Utilizng applications such as LinkedIn Learning or Coursera can assist with this.


#### Advanced 

At this stage, we will aim for constructing pipelines that are sufficient from beginning to end and that integrate a prouction quality result. As a final step, DataLemur provides candidates with interview questions that correspond to SQL and have been confirmed by various companies such as Amazon, Google, etc.


### OneStream

It is important to note that this is a private software application so receiving quality training will be difficult without being sponsored by a company.

#### Beginner 

Youtube is the best resource for beginning to familiarize yourself with the main functionality and goals of the software. The company does have their own channel, so it would be advised to watch their videos and learn more about what the application does and how it works.


#### Intermediate 

Consider purchasing an online course through Udemy or Keyteach. While this does require personal spending, it would be the easiest way to gain an understanding without requiring an official license to operate the software. This would help to practice working with the application and exploring key concepts.

#### Advanced

This stage would be difficult, because you would need access to the software in order to achieve an advanced level. If you are employed (especially in the financial services industry) consider asking IT for access. There you can work more on complicated structures such as macros and visualization.


### AWS

#### Beginner