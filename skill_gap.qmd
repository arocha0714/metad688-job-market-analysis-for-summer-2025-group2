---
title: Skill Gap Analysis
format:
    html:
        toc: true
        toc-depth: 2
execute:
  echo: false   
  warning: false  
  message: false   
  eval: false
---
```{python}
#| results: 'hide'
#| echo: false

import findspark
findspark.init()

from pyspark.sql import SparkSession
import pandas as pd
import plotly.express as px
import plotly.io as pio
import numpy as np

np.random.seed(42)

pio.renderers.default = "notebook"

# Initialize Spark Session
spark = SparkSession.builder.appName("LightcastData").getOrCreate()

# Load Data
df = spark.read.option("header", "true").option("inferSchema", "true").option("multiLine","true").option("escape", "\"").csv("./data/lightcast_job_postings.csv")



```

```{python}
#| echo: false

df.createOrReplaceTempView("jobs")
```

```{python}
#| results: 'hide'
#| echo: false
software_skill_counts_by_type = spark.sql("""
    SELECT software_skills_name, COUNT(*) AS count
    FROM jobs
    WHERE LOWER(title_name) LIKE '%analyst%'
       OR LOWER(title_name) LIKE '%analysis%'
       OR LOWER(title_name) LIKE '%analytics%'
    GROUP BY software_skills_name
    ORDER BY count DESC
    LIMIT 10
""")
software_skill_counts_by_type.show(truncate=False)
```

```{python}
#| results: 'hide'
#| echo: false
skill_counts_by_type = spark.sql("""
    SELECT skills_name, COUNT(*) AS count
    FROM jobs
    WHERE LOWER(title_name) LIKE '%analyst%'
    OR LOWER(title_name) LIKE '%analysis%'
    OR LOWER(title_name) LIKE '%analytics%'
    GROUP BY skills_name
    ORDER BY count DESC
    LIMIT 10
""")
skill_counts_by_type.show(truncate=False)
```

```{python}
#| results: 'hide'
#| echo: false
import pandas as pd

skills_data = {
    "Name": ["Alyssa", "Adam", "Yihan"],
    "Microsoft Office": [4, 5, 3],
    "Dashboard": [3, 3, 1],
    "SQL": [2, 2, 2],
    "OneStream": [1, 1, 1],
    "Cloud Computing": [2, 2, 2]
}

df_skills = pd.DataFrame(skills_data)
df_skills.set_index("Name", inplace=True)
df_skills
```


```{python}
#| eval: false
#| echo: false
#| warning: false
#| fig-cap: "Skillset Analysis"
#| fig-align: center
#| label: fig-analyst-distribution

import pandas as pd
import plotly.graph_objects as go

# Your data
skills_data = {
    "Name": ["Alyssa", "Adam", "Yihan"],
    "Microsoft Office": [4, 5, 3],
    "Dashboard": [3, 3, 1],
    "SQL": [2, 2, 2],
    "OneStream": [0, 0, 0],
    "Cloud Computing": [2, 2, 2]
}

# Create DataFrame
df_skills = pd.DataFrame(skills_data)
df_skills.set_index("Name", inplace=True)

# Get skill categories
categories = df_skills.columns.tolist()

# Create Plotly radar chart
fig = go.Figure()

for name in df_skills.index:
    values = df_skills.loc[name].tolist()
    values += values[:1]  # close the radar loop

    fig.add_trace(go.Scatterpolar(
        r=values,
        theta=categories + [categories[0]],  # close the loop
        fill='toself',
        name=name
    ))

# Customize layout
fig.update_layout(
    polar=dict(
        radialaxis=dict(
            visible=True,
            range=[0, 6]
        )),
    showlegend=True,
    title="Team Skillset Levels"
)
fig.show()


fig.write_html("./figures/skill_gap.html", include_plotlyjs='cdn')

#https://plotly.com/python/radar-chart/
```

```{=html}
<iframe width="1000" height="700" src="./figures/skill_gap.html" title="Market Comparison"></iframe>
```
# Recomendations

Given our analysis above, we have decided to focus on some of the key actions and learning goals that each of us can take in order to further our chances of landing a high quality position in our chosen industry.


### SQL

#### Beginner

We recommend using tools such as SQLBolt to begin developing a foundational understanding of basic syntax, queries, and selecting columns from datasets. This will build familiarity with the program itself and develop a confidence in import and simple manipulation of data.

#### Intermediate

Next, we will incorporate real-world data sets (ex. Kaggle) to begin creating analysis. As an example, you could utilize sales data, new customers, inventory levels, certain trends over time, etc. Utilizng applications such as LinkedIn Learning or Coursera can assist with this.


#### Advanced 

At this stage, we will aim for constructing pipelines that are sufficient from beginning to end and that integrate a prouction quality result. As a final step, DataLemur provides candidates with interview questions that correspond to SQL and have been confirmed by various companies such as Amazon, Google, etc.
