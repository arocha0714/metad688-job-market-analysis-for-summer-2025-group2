{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: Data Cleaning and Modeling\n",
        "format:\n",
        "    html:\n",
        "        code-fold: true\n",
        "        toc: true\n",
        "        toc-depth: 2\n",
        "exeucte:\n",
        "    eval: true\n",
        "    echo: false\n",
        "    freeze: auto\n",
        "---\n"
      ],
      "id": "5e9540cd"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "#| echo: false\n",
        "#| warning: false\n",
        "#| fig-cap: Analyst Job Distribution Across the United States\n",
        "#| fig-align: center\n",
        "#| label: fig-analyst-distribution-modeling\n",
        "import findspark\n",
        "findspark.init()\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import plotly.io as pio\n",
        "import numpy as np\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "pio.renderers.default = \"notebook\"\n",
        "\n",
        "# Initialize Spark Session\n",
        "spark = SparkSession.builder.appName(\"LightcastData\").getOrCreate()\n",
        "\n",
        "# Load Data\n",
        "df = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").option(\"multiLine\",\"true\").option(\"escape\", \"\\\"\").csv(\"./data/lightcast_job_postings.csv\")\n",
        "\n",
        "# Show Schema and Sample Data\n",
        "print(\"---This is Diagnostic check, No need to print it in the final doc---\")\n",
        "\n",
        "df.printSchema() # comment this line when rendering the submission\n",
        "df.show(5)"
      ],
      "id": "fig-analyst-distribution-modeling",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "results": "hide"
      },
      "source": [
        "#| echo: false\n",
        "#| warning: false\n",
        "#| eval: false\n",
        "\n",
        "import pandas as pd\n",
        "df = pd.read_csv(\"./data/lightcast_job_postings.csv\")"
      ],
      "id": "5fa2535a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "results": "hide"
      },
      "source": [
        "#| echo: false\n",
        "#| warning: false\n",
        "#| eval: false\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"./data/lightcast_job_postings.csv\")\n",
        "\n",
        "columns_to_drop = [\n",
        "    \"ID\", \"URL\", \"ACTIVE_URLS\", \"DUPLICATES\", \"LAST_UPDATED_TIMESTAMP\",\n",
        "    \"NAICS2\", \"NAICS3\", \"NAICS4\", \"NAICS5\", \"NAICS6\",\n",
        "    \"SOC_2\", \"SOC_3\", \"SOC_5\"\n",
        "]\n",
        "\n",
        "df.drop(columns=columns_to_drop, inplace=True)"
      ],
      "id": "6c2537c3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "results": "hide"
      },
      "source": [
        "#| echo: false\n",
        "#| warning: false\n",
        "#| eval: false\n",
        "\n",
        "print(df.columns.tolist())"
      ],
      "id": "90c242ed",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "results": "hide"
      },
      "source": [
        "#| echo: false\n",
        "#| warning: false\n",
        "#| eval: false\n",
        "!pip install missingno"
      ],
      "id": "98208483",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "results": "hide"
      },
      "source": [
        "#| eval: false\n",
        "#| echo: false\n",
        "#| warning: false\n",
        "import missingno as msno\n",
        "import matplotlib.pyplot as plt\n",
        "# Visualize missing values\n",
        "msno.heatmap(df)\n",
        "plt.title(\"Missing Values Heatmap\")\n",
        "plt.show()\n",
        "\n",
        "# Drop columns with >50% missing values\n",
        "df.dropna(thresh=len(df) * 0.5, axis=1, inplace=True)\n",
        "\n",
        "# Fill only the columns you actually have\n",
        "if 'Industry' in df.columns:\n",
        "    df[\"Industry\"].fillna(\"Unknown\", inplace=True)\n",
        "    df[\"Salary\"].fillna(df[\"Salary\"].median(), inplace=True)"
      ],
      "id": "037d4bee",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "results": "hide"
      },
      "source": [
        "#| eval: false\n",
        "#| echo: false\n",
        "#| warning: false\n",
        "df = df.drop_duplicates(subset=[\"TITLE\", \"COMPANY\", \"LOCATION\", \"POSTED\"], keep=\"first\")"
      ],
      "id": "9d433fc0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "results": "hide"
      },
      "source": [
        "#| eval: false\n",
        "#| echo: false\n",
        "#| warning: false\n",
        "df = df[df['NAICS_2022_2_NAME'] != 'Unclassified Industry']"
      ],
      "id": "dae1ba95",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "results": "hide"
      },
      "source": [
        "#| eval: false\n",
        "#| echo: false\n",
        "#| warning: false\n",
        "df['REMOTE_TYPE_NAME'] = df['REMOTE_TYPE_NAME'].replace('[None]', 'Not Remote')\n"
      ],
      "id": "97939af7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "results": "hide"
      },
      "source": [
        "#| eval: false\n",
        "#| echo: false\n",
        "#| warning: false\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "\n",
        "# Step 1: Prepare data\n",
        "data = {\n",
        "    'Industry': [\n",
        "        'Wholesale Trade', 'Retail Trade', 'Real Estate and Rental and Leasing',\n",
        "        'Professional, Scientific, and Technical Services', 'Manufacturing',\n",
        "        'Information', 'Health Care and Social Assistance',\n",
        "        'Finance and Insurance', 'Educational Services',\n",
        "        'Administrative and Support and Waste Management and Remediation Services'\n",
        "    ],\n",
        "    'Flexible Remote': [87.8, 94.4, 97.6, 92.2, 89.7, 95.8, 92.1, 94.8, 89.0, 94.8],\n",
        "    'Onsite': [12.2, 5.6, 2.4, 7.8, 10.3, 4.2, 7.9, 5.2, 11.0, 5.2]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Step 2: Sort in ascending order of Flexible Remote\n",
        "df_sorted = df.sort_values(by='Flexible Remote', ascending=True)\n",
        "df_sorted['Industry'] = pd.Categorical(df_sorted['Industry'], categories=df_sorted['Industry'], ordered=True)\n",
        "\n",
        "# Step 3: Melt data for stacked bar format\n",
        "df_melted = df_sorted.melt(\n",
        "    id_vars='Industry',\n",
        "    value_vars=['Flexible Remote', 'Onsite'],\n",
        "    var_name='Remote Type',\n",
        "    value_name='Percentage'\n",
        ")\n",
        "\n",
        "# Step 4: Plot\n",
        "fig = px.bar(\n",
        "    df_melted,\n",
        "    x='Percentage',\n",
        "    y='Industry',\n",
        "    color='Remote Type',\n",
        "    orientation='h',\n",
        "    text='Percentage',\n",
        "    color_discrete_map={\n",
        "        'Flexible Remote': '#1aab89',\n",
        "        'Onsite': '#88d4c3'\n",
        "    },\n",
        "    title=\"Remote Job Distribution by Industry (Top 10 Industries)\"\n",
        ")\n",
        "\n",
        "# Step 5: Layout adjustments\n",
        "fig.update_layout(\n",
        "    xaxis_title=\"Percentage of Jobs\",\n",
        "    yaxis_title=\"\",\n",
        "    xaxis=dict(tickformat=\".0f\"),\n",
        "    legend_title=\"Remote Type\",\n",
        "    barmode='stack',\n",
        "    margin=dict(l=10, r=10, t=60, b=40),\n",
        "    height=500\n",
        ")\n",
        "\n",
        "# Step 6: Label formatting\n",
        "fig.update_traces(texttemplate='%{text:.1f}%', textposition='inside')\n",
        "\n",
        "# Save plot\n",
        "fig.write_html(\"./figures/top_industries.html\")\n",
        "\n",
        "\n",
        "# Show plot\n",
        "fig.show()\n"
      ],
      "id": "9ab17db8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "#| echo: false\n",
        "#| warning: false\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix, f1_score, accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "id": "8da96818",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "#| echo: false\n",
        "#| warning: false\n",
        "#read files\n",
        "file_path = \"./data/lightcast_job_postings.csv\"\n",
        "df = pd.read_csv(file_path)"
      ],
      "id": "66d6a405",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "#| echo: false\n",
        "#| warning: false\n",
        "print(df['REMOTE_TYPE_NAME'].value_counts(dropna=False).head(10))"
      ],
      "id": "a2a3349c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "#| echo: false\n",
        "#| warning: false\n",
        "# Step 1: Standardize formatting\n",
        "df['REMOTE_TYPE_NAME'] = (\n",
        "    df['REMOTE_TYPE_NAME']\n",
        "    .astype(str)\n",
        "    .str.strip()\n",
        "    .str.title()\n",
        "    .replace({'None': pd.NA, 'Nan': pd.NA})\n",
        ")"
      ],
      "id": "948b19da",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "#| echo: false\n",
        "#| warning: false\n",
        "# Step 2: Fill missing or ambiguous entries with 'Not Remote'\n",
        "df['REMOTE_TYPE_NAME'] = df['REMOTE_TYPE_NAME'].fillna('Not Remote')\n",
        "df.loc[df['REMOTE_TYPE_NAME'] == \"[None]\", 'REMOTE_TYPE_NAME'] = \"Not Remote\"\n",
        "print(df['REMOTE_TYPE_NAME'].value_counts(dropna=False).head(10))"
      ],
      "id": "b38298b8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "#| echo: false\n",
        "#| warning: false\n",
        "# Convert all values to strings and strip whitespace\n",
        "df['REMOTE_TYPE_NAME'] = df['REMOTE_TYPE_NAME'].astype(str).str.strip()"
      ],
      "id": "86219d1f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "#| echo: false\n",
        "#| warning: false\n",
        "# Apply new classification logic\n",
        "df['REMOTE_BINARY'] = df['REMOTE_TYPE_NAME'].apply(\n",
        "    lambda x: 1 if x in ['Remote', 'Hybrid Remote'] else 0\n",
        ")"
      ],
      "id": "b24f209b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "#| echo: false\n",
        "#| warning: false\n",
        "print(df['REMOTE_TYPE_NAME'].value_counts())\n",
        "print(\"\\nBinary classification:\")\n",
        "print(df['REMOTE_BINARY'].value_counts())"
      ],
      "id": "4e852b79",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "#| echo: false\n",
        "#| warning: false\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Ensure salary columns are numeric and handle missing values\n",
        "df['SALARY_FROM'] = pd.to_numeric(df['SALARY_FROM'], errors='coerce').replace(0, np.nan)\n",
        "df['SALARY_TO'] = pd.to_numeric(df['SALARY_TO'], errors='coerce').replace(0, np.nan)\n",
        "\n",
        "# Calculate average salary (mean of SALARY_FROM and SALARY_TO)\n",
        "df['AVERAGE_SALARY'] = df[['SALARY_FROM', 'SALARY_TO']].mean(axis=1)\n",
        "\n",
        "# Drop rows with missing values in AVERAGE_SALARY, REMOTE_TYPE_NAME, or STATE_NAME\n",
        "df_salary = df.dropna(subset=['AVERAGE_SALARY', 'REMOTE_TYPE_NAME', 'STATE_NAME'])\n",
        "\n",
        "# Group by state and remote type, then calculate average salary\n",
        "avg_salary_by_state_remote = df_salary.groupby(['STATE_NAME', 'REMOTE_TYPE_NAME'])['AVERAGE_SALARY'].mean().reset_index()\n",
        "\n",
        "# Round the results for easier reading\n",
        "avg_salary_by_state_remote['AVERAGE_SALARY'] = avg_salary_by_state_remote['AVERAGE_SALARY'].round(2)\n",
        "\n",
        "# Show results\n",
        "print(avg_salary_by_state_remote)"
      ],
      "id": "d1bb6bad",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "#| echo: false\n",
        "#| warning: false\n",
        "df = df.merge(avg_salary_by_state_remote,\n",
        "              on=['STATE_NAME', 'REMOTE_TYPE_NAME'],\n",
        "              how='left')"
      ],
      "id": "9f2e0297",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "#| echo: false\n",
        "#| warning: false\n",
        "df = df.merge(\n",
        "    avg_salary_by_state_remote,\n",
        "    on=['STATE_NAME', 'REMOTE_TYPE_NAME'],\n",
        "    how='left',\n",
        "    suffixes=('', '_STATE_REMOTE_AVG')\n",
        ")"
      ],
      "id": "09abbf26",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "#| echo: false\n",
        "#| warning: false\n",
        "[col for col in df.columns if 'AVG' in col or 'SALARY' in col]"
      ],
      "id": "843af78e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "#| echo: false\n",
        "#| warning: false\n",
        "df = df.rename(columns={'AVERAGE_SALARY_y': 'AVERAGE_SALARY_STATE_REMOTE_AVG'})"
      ],
      "id": "4c699814",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "#| echo: false\n",
        "#| warning: false\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import (accuracy_score, f1_score, confusion_matrix,\n",
        "                             classification_report, precision_score,\n",
        "                             recall_score, balanced_accuracy_score)\n",
        "from sklearn.inspection import permutation_importance\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ],
      "id": "e080f598",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "#| echo: false\n",
        "#| warning: false\n",
        "# Remove duplicate column names across full dataframe\n",
        "df = df.loc[:, ~df.columns.duplicated()]"
      ],
      "id": "4001bd21",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "#| echo: false\n",
        "#| warning: false\n",
        "df['AVG_YEARS_EXPERIENCE'] = (df['MIN_YEARS_EXPERIENCE'] + df['MAX_YEARS_EXPERIENCE']) / 2\n",
        "df['EXP_SPREAD'] = df['MAX_YEARS_EXPERIENCE'] - df['MIN_YEARS_EXPERIENCE']"
      ],
      "id": "f3d57a1c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "#| echo: false\n",
        "#| warning: false\n",
        "df = df.drop(columns=['MIN_YEARS_EXPERIENCE', 'MAX_YEARS_EXPERIENCE'])"
      ],
      "id": "90b4495c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "#| echo: false\n",
        "#| warning: false\n",
        "num_feats = [\n",
        "    'AVG_YEARS_EXPERIENCE',\n",
        "    'AVERAGE_SALARY_STATE_REMOTE_AVG',\n",
        "    'IS_INTERNSHIP'\n",
        "]\n",
        "\n",
        "cat_feats = [\n",
        "    'STATE_NAME',\n",
        "    'NAICS_2022_2_NAME',\n",
        "    'EDUCATION_LEVELS_NAME',\n",
        "    'COMMON_SKILLS_NAME',\n",
        "    'SOFTWARE_SKILLS_NAME',\n",
        "    'TITLE_CLEAN'\n",
        "    \n",
        "]\n",
        "\n",
        "X = df[num_feats + cat_feats]\n",
        "y = df['REMOTE_BINARY']"
      ],
      "id": "8ad50bbf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "#| echo: false\n",
        "#| warning: false\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "id": "d91d6494",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "#| echo: false\n",
        "#| warning: false\n",
        "preprocess = ColumnTransformer(transformers=[\n",
        "    (\"num\", StandardScaler(), num_feats),\n",
        "    (\"cat\", OneHotEncoder(handle_unknown='ignore', sparse_output=False), cat_feats)\n",
        "])"
      ],
      "id": "74225eb8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "#| echo: false\n",
        "#| warning: false\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")"
      ],
      "id": "1f34075f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "#| echo: false\n",
        "#| warning: false\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "# Preprocessing step\n",
        "preprocess = ColumnTransformer(transformers=[\n",
        "    (\"num\", StandardScaler(), num_feats),\n",
        "    (\"cat\", OneHotEncoder(handle_unknown='ignore', max_categories=500, sparse_output=False), cat_feats)\n",
        "])\n",
        "clf = RandomForestClassifier(random_state=42, class_weight='balanced')"
      ],
      "id": "d2f5d046",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "#| echo: false\n",
        "#| warning: false\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "rf = RandomForestClassifier(\n",
        "    n_estimators=200,\n",
        "    max_depth=None,\n",
        "    class_weight='balanced',\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "pipe = Pipeline(steps=[\n",
        "    ('prep', preprocess),\n",
        "    ('model', rf)\n",
        "])"
      ],
      "id": "f86b8e6a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "#| echo: false\n",
        "#| warning: false\n",
        "pipe.fit(X_train, y_train)"
      ],
      "id": "0ad09a55",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "#| echo: false\n",
        "#| warning: false\n",
        "y_pred = pipe.predict(X_test)\n",
        "\n",
        "# Classification report and confusion matrix\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "# Additional custom metrics\n",
        "print(\"\\nCustom Metrics:\")\n",
        "print(\"Accuracy:\", round(accuracy_score(y_test, y_pred), 3))\n",
        "print(\"F1 Score:\", round(f1_score(y_test, y_pred), 3))\n",
        "print(\"Precision:\", round(precision_score(y_test, y_pred), 3))\n",
        "print(\"Sensitivity (Recall 1):\", round(recall_score(y_test, y_pred), 3))\n",
        "print(\"Specificity (Recall 0):\", round(\n",
        "    recall_score(y_test, y_pred, pos_label=0), 3))\n",
        "print(\"Balanced Accuracy:\", round(balanced_accuracy_score(y_test, y_pred), 3))\n"
      ],
      "id": "dbc2fe34",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "#| echo: false\n",
        "#| warning: false\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"True\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()"
      ],
      "id": "69742a7f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "#| echo: false\n",
        "#| warning: false\n",
        "rf_model       = pipe.named_steps[\"model\"]          # RandomForestClassifier\n",
        "feature_names  = pipe.named_steps[\"prep\"].get_feature_names_out()\n",
        "\n",
        "importances = rf_model.feature_importances_\n",
        "\n",
        "feat_imp = (\n",
        "    pd.DataFrame({\"Feature\": feature_names, \"Importance\": importances})\n",
        "      .sort_values(by=\"Importance\", ascending=False)\n",
        "      .reset_index(drop=True)\n",
        ")\n",
        "\n",
        "print(\"\\nTop 9 – Tree-based Importances\")\n",
        "print(feat_imp.head(9).to_string(index=False))"
      ],
      "id": "2995adef",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "#| echo: false\n",
        "#| warning: false\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "top_n = 9                     # change to show more/less\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.barplot(\n",
        "    data=feat_imp.head(top_n),\n",
        "    x=\"Importance\", y=\"Feature\",\n",
        "    palette=\"crest\"\n",
        ")\n",
        "plt.title(f\"Top {top_n} Feature Importances (Random Forest)\")\n",
        "plt.xlabel(\"Mean Decrease in Impurity\")\n",
        "plt.ylabel(\"\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "36f44fa8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "#| echo: false\n",
        "#| warning: false\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "\n",
        "# Step 1: Create state abbreviation mapping\n",
        "us_state_abbrev = {\n",
        "    'Alabama': 'AL', 'Alaska': 'AK', 'Arizona': 'AZ', 'Arkansas': 'AR',\n",
        "    'California': 'CA', 'Colorado': 'CO', 'Connecticut': 'CT', 'Delaware': 'DE',\n",
        "    'Florida': 'FL', 'Georgia': 'GA', 'Hawaii': 'HI', 'Idaho': 'ID',\n",
        "    'Illinois': 'IL', 'Indiana': 'IN', 'Iowa': 'IA', 'Kansas': 'KS',\n",
        "    'Kentucky': 'KY', 'Louisiana': 'LA', 'Maine': 'ME', 'Maryland': 'MD',\n",
        "    'Massachusetts': 'MA', 'Michigan': 'MI', 'Minnesota': 'MN', 'Mississippi': 'MS',\n",
        "    'Missouri': 'MO', 'Montana': 'MT', 'Nebraska': 'NE', 'Nevada': 'NV',\n",
        "    'New Hampshire': 'NH', 'New Jersey': 'NJ', 'New Mexico': 'NM', 'New York': 'NY',\n",
        "    'North Carolina': 'NC', 'North Dakota': 'ND', 'Ohio': 'OH', 'Oklahoma': 'OK',\n",
        "    'Oregon': 'OR', 'Pennsylvania': 'PA', 'Rhode Island': 'RI', 'South Carolina': 'SC',\n",
        "    'South Dakota': 'SD', 'Tennessee': 'TN', 'Texas': 'TX', 'Utah': 'UT',\n",
        "    'Vermont': 'VT', 'Virginia': 'VA', 'Washington': 'WA', 'West Virginia': 'WV',\n",
        "    'Wisconsin': 'WI', 'Wyoming': 'WY', 'District of Columbia': 'DC'\n",
        "}\n",
        "\n",
        "# Step 2: Map state names to abbreviations\n",
        "df['STATE_ABBR'] = df['STATE_NAME'].map(us_state_abbrev)\n",
        "\n",
        "# Step 3: Group by state and compute metrics\n",
        "choropleth_data = df.groupby('STATE_ABBR').agg(\n",
        "    remote_ratio=('REMOTE_BINARY', 'mean'),\n",
        "    avg_salary=('AVERAGE_SALARY_STATE_REMOTE_AVG', 'mean'),\n",
        "    avg_experience=('AVG_YEARS_EXPERIENCE', 'mean'),\n",
        "    job_count=('STATE_NAME', 'count')\n",
        ").reset_index()\n",
        "\n",
        "# Step 4: Define custom green scale (start from light, move to #1aab89)\n",
        "custom_green_scale = [\n",
        "    [0, \"#e0f7f1\"],     # light mint\n",
        "    [0.5, \"#70d8b5\"],   # mid-green\n",
        "    [1, \"#1aab89\"]      # deep teal green\n",
        "]\n",
        "\n",
        "# Step 5: Create the choropleth with custom green\n",
        "fig = px.choropleth(\n",
        "    data_frame=choropleth_data,\n",
        "    locations='STATE_ABBR',\n",
        "    locationmode=\"USA-states\",\n",
        "    color='remote_ratio',\n",
        "    color_continuous_scale=custom_green_scale,\n",
        "    scope=\"usa\",\n",
        "    labels={'remote_ratio': 'Remote Job Ratio'},\n",
        "    hover_data={\n",
        "        'remote_ratio': ':.2f',\n",
        "        'avg_salary': ':.0f',\n",
        "        'avg_experience': ':.1f',\n",
        "        'job_count': True\n",
        "    },\n",
        "    title='Remote Job Ratio by State (Custom Green), Avg Salary & Experience in Hover'\n",
        ")\n",
        "\n",
        "fig.update_layout(margin={\"r\":0,\"t\":40,\"l\":0,\"b\":0})\n",
        "fig.write_html(\"./figures/state_remote_job_ratio.html\")\n",
        "\n",
        "fig.show()\n"
      ],
      "id": "cada88f7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "#| echo: false\n",
        "#| warning: false\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Step 1: Ensure 'POSTED' is in datetime format and create Year-Month\n",
        "df['POSTED'] = pd.to_datetime(df['POSTED'])\n",
        "df['POSTED_YM'] = df['POSTED'].dt.to_period('M').astype(str)"
      ],
      "id": "24a1ab07",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "#| echo: false\n",
        "#| warning: false\n",
        "industry_trends = (\n",
        "    df.groupby(['NAICS_2022_2_NAME', 'POSTED_YM'])['REMOTE_BINARY']\n",
        "    .mean()\n",
        "    .reset_index(name='REMOTE_RATIO')\n",
        ")"
      ],
      "id": "539b3974",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "#| echo: false\n",
        "#| warning: false\n",
        "# Step 3: Select top 5 industries with highest overall average remote ratio\n",
        "top_industries = (\n",
        "    industry_trends.groupby('NAICS_2022_2_NAME')['REMOTE_RATIO']\n",
        "    .mean()\n",
        "    .sort_values(ascending=False)\n",
        "    .head(5)\n",
        "    .index.tolist()\n",
        ")\n",
        "filtered_trends = industry_trends[industry_trends['NAICS_2022_2_NAME'].isin(top_industries)]"
      ],
      "id": "3a2a7707",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "#| echo: false\n",
        "#| warning: false\n",
        "import plotly.express as px\n",
        "\n",
        "fig = px.line(\n",
        "    filtered_trends,\n",
        "    x='POSTED_YM',\n",
        "    y='REMOTE_RATIO',\n",
        "    color='NAICS_2022_2_NAME',\n",
        "    markers=True,\n",
        "    title=\"Top Industries: Remote Job Trends Over Time\"\n",
        ")\n",
        "\n",
        "fig.update_layout(\n",
        "    xaxis_title=\"Posted Month\",\n",
        "    yaxis_title=\"Remote Job Ratio\",\n",
        "    legend_title=\"Industry\",\n",
        "    legend=dict(x=1.02, y=1, bordercolor=\"Black\"),\n",
        "    margin=dict(l=40, r=40, t=60, b=40),\n",
        "    width=1000,\n",
        "    height=500\n",
        ")\n",
        "\n",
        "fig.update_xaxes(tickangle=45)\n",
        "fig.write_html(\"./figures/remote_job_over_time.html\")\n",
        "fig.show()"
      ],
      "id": "2b59de30",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "#| echo: false\n",
        "#| warning: false\n",
        "#Groupby industry + month and calculate both:\n",
        "industry_month_stats = df.groupby(['NAICS_2022_2_NAME', 'POSTED_YM']).agg(\n",
        "    TOTAL_JOBS=('REMOTE_BINARY', 'count'),\n",
        "    REMOTE_RATIO=('REMOTE_BINARY', 'mean')\n",
        ").reset_index()"
      ],
      "id": "eb1989de",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "#| echo: false\n",
        "#| warning: false\n",
        "job_count = df.groupby(['NAICS_2022_2_NAME', 'POSTED_YM']).size().reset_index(name='JOB_COUNT')"
      ],
      "id": "a8d991b8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "#| echo: false\n",
        "#| warning: false\n",
        "remote_ratio = df.groupby(['NAICS_2022_2_NAME', 'POSTED_YM'])['REMOTE_BINARY'].mean().reset_index(name='REMOTE_RATIO')"
      ],
      "id": "66811175",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "#| echo: false\n",
        "#| warning: false\n",
        "industry_month_stats = pd.merge(remote_ratio, job_count, on=['NAICS_2022_2_NAME', 'POSTED_YM'])"
      ],
      "id": "6b0456ff",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "#| echo: false\n",
        "#| warning: false\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Choose 2–3 industries to plot (or loop one at a time)\n",
        "selected_industries = [\n",
        "    'Administrative and Support and Waste Management and Remediation Services',\n",
        "    'Arts, Entertainment, and Recreation',\n",
        "    'Finance and Insurance',\n",
        "    'Real Estate and Rental and Leasing',\n",
        "    'Utilities'\n",
        "]\n",
        "\n",
        "\n",
        "\n",
        "for industry in selected_industries:\n",
        "    data = industry_month_stats[industry_month_stats['NAICS_2022_2_NAME'] == industry]  \n",
        "\n",
        "    fig, ax1 = plt.subplots(figsize=(10, 4))\n",
        "\n",
        "    # Plot remote ratio\n",
        "    ax1.plot(data['POSTED_YM'], data['REMOTE_RATIO'], color='tab:blue', marker='o')\n",
        "    ax1.set_xlabel('Month')\n",
        "    ax1.set_ylabel('Remote Job Ratio', color='tab:blue')\n",
        "    ax1.tick_params(axis='y', labelcolor='tab:blue')\n",
        "    ax1.set_title(f\"Remote Job Ratio & Volume Over Time: {industry}\")\n",
        "\n",
        "    # Plot job count on secondary y-axis\n",
        "    ax2 = ax1.twinx()\n",
        "    ax2.bar(data['POSTED_YM'], data['JOB_COUNT'], color='tab:gray', alpha=0.3)\n",
        "    ax2.set_ylabel('Total Job Postings', color='gray')\n",
        "    ax2.tick_params(axis='y', labelcolor='gray')\n",
        "\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(\"./figures/Remote_jobs_\"+str(industry)+\".jpg\", dpi=300)\n",
        "    plt.show()\n"
      ],
      "id": "f1477d61",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Random Forest results \n",
        "\n",
        "![Random Forest results](./figures/classification_report.png){width=90% fig-align=\"center\"}\n",
        "![Confustion Matrix](./figures/Confusion_matrix.png){width=90% fig-align=\"center\"}\n",
        "As the two plots displayed a clear results for random forest results, our group has set our target variable for predict people's preferences on Remote versus Onsite job, where 1 represents a remote job and 0 represents onsite. We also had a set of independent variables, including as: 'AVG_YEARS_EXPERIENCE', 'AVERAGE_SALARY_STATE_REMOTE_AVG', 'IS_INTERNSHIP', 'STATE_NAME', 'NAICS_2022_2_NAME'(industry) 'EDUCATION_LEVELS_NAME', 'COMMON_SKILLS_NAME',  'SOFTWARE_SKILLS_NAME',  'TITLE_CLEAN' (occupation). Meanwhile, we split the data into training and testing sets using an 80/20 ratio to ensure generalizability, This means 20% of the data will go into the test set, and 80% will go into the training set. Then we conduct the randam forest model analysis.\n",
        "According to plots, we can conclude the accuracy reached to 94.6%;F1 score as 84.7%, which reflects the robust balance between precision and recall; the precision as 99.4%, which means it has highly accurate rate on predict the results;the sensitivity for class1 as 73.8%, which means it correctly identified the 74% people who pick remote; the sensitivity for class 0 even reached to 99.9%, which means almost all the people who choose non-remote job has correctly classified; balanced accuracy as 86.8%, which represents there is a balance performance between both cases. \n",
        "From the confusion matrix, there has a detailed display, which represents the model correctly predicts 11536 people who choose onsite jobs with only 13 false positives, and it also orrectly predicts 2177 people who choose remote jobs with 774 missed results.\n",
        "\n",
        "One major limitation is class imbalance. Remote jobs (class 1) are the minority, which leads the model to perform less effectively on them.To counter this, we used class_weight='balanced' in our Random Forest to give more weight to underrepresented classes. We also built a preprocessing pipeline using ColumnTransformer for encoding categorical and scaling numerical features.Still, further optimization is needed. we recommended three ways to overcome this issue in the future study: Adjusting sample sizes;Tuning model hyperparameters, like n_estimators and max_categories;  experimenting with resampling techniques; add crossvalidation steps to void overfitting and ensure the final results' accuracy.\n",
        "\n",
        "#### Featured Importance\n",
        "![Featured importance](./figures/Featured_importance.png){width=90% fig-align=\"center\"}\n",
        "Based on the above plot, we can see the top 9 features could be essential in predicting the peoples'prefrences on remote or onsite jobs, we can see the top three essential features are average remote salary by state, Average years of experience and location state-California. These three features can be easily interpreted as the job's salary, job's requirement for year experiences and location are vital elements that impact people's decision on onsite or remote job types, peple prioritize jobs with high salary and better geographic location\n"
      ],
      "id": "95943298"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "#| echo: false\n",
        "#| warning: false\n",
        "\n",
        "import os\n",
        "\n",
        "file_path = './data/lightcast_job_postings.csv'\n",
        "if not os.path.exists(file_path):\n",
        "    raise FileNotFoundError(f\"Missing file: {file_path}\")"
      ],
      "id": "de9f0e1a",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)",
      "path": "C:\\Program Files\\Python312\\share\\jupyter\\kernels\\python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}