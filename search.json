[
  {
    "objectID": "geographic_analysis.html",
    "href": "geographic_analysis.html",
    "title": "Geographic Analysis",
    "section": "",
    "text": "Introduction\nbla balal\n\n\nimport findspark\nfindspark.init()\n\nfrom pyspark.sql import SparkSession\nimport pandas as pd\nimport plotly.express as px\nimport plotly.io as pio\nimport numpy as np\n\nnp.random.seed(42)\n\npio.renderers.default = \"notebook\"\n\n# Initialize Spark Session\nspark = SparkSession.builder.appName(\"LightcastData\").getOrCreate()\n\n# Load Data\ndf = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").option(\"multiLine\",\"true\").option(\"escape\", \"\\\"\").csv(\"./data/lightcast_job_postings.csv\")\n\n# Show Schema and Sample Data\nprint(\"---This is Diagnostic check, No need to print it in the final doc---\")\n\ndf.printSchema() # comment this line when rendering the submission\ndf.show(5)\n\n                                                                                \n\n\n---This is Diagnostic check, No need to print it in the final doc---\nroot\n |-- ID: string (nullable = true)\n |-- LAST_UPDATED_DATE: string (nullable = true)\n |-- LAST_UPDATED_TIMESTAMP: timestamp (nullable = true)\n |-- DUPLICATES: integer (nullable = true)\n |-- POSTED: string (nullable = true)\n |-- EXPIRED: string (nullable = true)\n |-- DURATION: integer (nullable = true)\n |-- SOURCE_TYPES: string (nullable = true)\n |-- SOURCES: string (nullable = true)\n |-- URL: string (nullable = true)\n |-- ACTIVE_URLS: string (nullable = true)\n |-- ACTIVE_SOURCES_INFO: string (nullable = true)\n |-- TITLE_RAW: string (nullable = true)\n |-- BODY: string (nullable = true)\n |-- MODELED_EXPIRED: string (nullable = true)\n |-- MODELED_DURATION: integer (nullable = true)\n |-- COMPANY: integer (nullable = true)\n |-- COMPANY_NAME: string (nullable = true)\n |-- COMPANY_RAW: string (nullable = true)\n |-- COMPANY_IS_STAFFING: boolean (nullable = true)\n |-- EDUCATION_LEVELS: string (nullable = true)\n |-- EDUCATION_LEVELS_NAME: string (nullable = true)\n |-- MIN_EDULEVELS: integer (nullable = true)\n |-- MIN_EDULEVELS_NAME: string (nullable = true)\n |-- MAX_EDULEVELS: integer (nullable = true)\n |-- MAX_EDULEVELS_NAME: string (nullable = true)\n |-- EMPLOYMENT_TYPE: integer (nullable = true)\n |-- EMPLOYMENT_TYPE_NAME: string (nullable = true)\n |-- MIN_YEARS_EXPERIENCE: integer (nullable = true)\n |-- MAX_YEARS_EXPERIENCE: integer (nullable = true)\n |-- IS_INTERNSHIP: boolean (nullable = true)\n |-- SALARY: integer (nullable = true)\n |-- REMOTE_TYPE: integer (nullable = true)\n |-- REMOTE_TYPE_NAME: string (nullable = true)\n |-- ORIGINAL_PAY_PERIOD: string (nullable = true)\n |-- SALARY_TO: integer (nullable = true)\n |-- SALARY_FROM: integer (nullable = true)\n |-- LOCATION: string (nullable = true)\n |-- CITY: string (nullable = true)\n |-- CITY_NAME: string (nullable = true)\n |-- COUNTY: integer (nullable = true)\n |-- COUNTY_NAME: string (nullable = true)\n |-- MSA: integer (nullable = true)\n |-- MSA_NAME: string (nullable = true)\n |-- STATE: integer (nullable = true)\n |-- STATE_NAME: string (nullable = true)\n |-- COUNTY_OUTGOING: integer (nullable = true)\n |-- COUNTY_NAME_OUTGOING: string (nullable = true)\n |-- COUNTY_INCOMING: integer (nullable = true)\n |-- COUNTY_NAME_INCOMING: string (nullable = true)\n |-- MSA_OUTGOING: integer (nullable = true)\n |-- MSA_NAME_OUTGOING: string (nullable = true)\n |-- MSA_INCOMING: integer (nullable = true)\n |-- MSA_NAME_INCOMING: string (nullable = true)\n |-- NAICS2: integer (nullable = true)\n |-- NAICS2_NAME: string (nullable = true)\n |-- NAICS3: integer (nullable = true)\n |-- NAICS3_NAME: string (nullable = true)\n |-- NAICS4: integer (nullable = true)\n |-- NAICS4_NAME: string (nullable = true)\n |-- NAICS5: integer (nullable = true)\n |-- NAICS5_NAME: string (nullable = true)\n |-- NAICS6: integer (nullable = true)\n |-- NAICS6_NAME: string (nullable = true)\n |-- TITLE: string (nullable = true)\n |-- TITLE_NAME: string (nullable = true)\n |-- TITLE_CLEAN: string (nullable = true)\n |-- SKILLS: string (nullable = true)\n |-- SKILLS_NAME: string (nullable = true)\n |-- SPECIALIZED_SKILLS: string (nullable = true)\n |-- SPECIALIZED_SKILLS_NAME: string (nullable = true)\n |-- CERTIFICATIONS: string (nullable = true)\n |-- CERTIFICATIONS_NAME: string (nullable = true)\n |-- COMMON_SKILLS: string (nullable = true)\n |-- COMMON_SKILLS_NAME: string (nullable = true)\n |-- SOFTWARE_SKILLS: string (nullable = true)\n |-- SOFTWARE_SKILLS_NAME: string (nullable = true)\n |-- ONET: string (nullable = true)\n |-- ONET_NAME: string (nullable = true)\n |-- ONET_2019: string (nullable = true)\n |-- ONET_2019_NAME: string (nullable = true)\n |-- CIP6: string (nullable = true)\n |-- CIP6_NAME: string (nullable = true)\n |-- CIP4: string (nullable = true)\n |-- CIP4_NAME: string (nullable = true)\n |-- CIP2: string (nullable = true)\n |-- CIP2_NAME: string (nullable = true)\n |-- SOC_2021_2: string (nullable = true)\n |-- SOC_2021_2_NAME: string (nullable = true)\n |-- SOC_2021_3: string (nullable = true)\n |-- SOC_2021_3_NAME: string (nullable = true)\n |-- SOC_2021_4: string (nullable = true)\n |-- SOC_2021_4_NAME: string (nullable = true)\n |-- SOC_2021_5: string (nullable = true)\n |-- SOC_2021_5_NAME: string (nullable = true)\n |-- LOT_CAREER_AREA: integer (nullable = true)\n |-- LOT_CAREER_AREA_NAME: string (nullable = true)\n |-- LOT_OCCUPATION: integer (nullable = true)\n |-- LOT_OCCUPATION_NAME: string (nullable = true)\n |-- LOT_SPECIALIZED_OCCUPATION: integer (nullable = true)\n |-- LOT_SPECIALIZED_OCCUPATION_NAME: string (nullable = true)\n |-- LOT_OCCUPATION_GROUP: integer (nullable = true)\n |-- LOT_OCCUPATION_GROUP_NAME: string (nullable = true)\n |-- LOT_V6_SPECIALIZED_OCCUPATION: integer (nullable = true)\n |-- LOT_V6_SPECIALIZED_OCCUPATION_NAME: string (nullable = true)\n |-- LOT_V6_OCCUPATION: integer (nullable = true)\n |-- LOT_V6_OCCUPATION_NAME: string (nullable = true)\n |-- LOT_V6_OCCUPATION_GROUP: integer (nullable = true)\n |-- LOT_V6_OCCUPATION_GROUP_NAME: string (nullable = true)\n |-- LOT_V6_CAREER_AREA: integer (nullable = true)\n |-- LOT_V6_CAREER_AREA_NAME: string (nullable = true)\n |-- SOC_2: string (nullable = true)\n |-- SOC_2_NAME: string (nullable = true)\n |-- SOC_3: string (nullable = true)\n |-- SOC_3_NAME: string (nullable = true)\n |-- SOC_4: string (nullable = true)\n |-- SOC_4_NAME: string (nullable = true)\n |-- SOC_5: string (nullable = true)\n |-- SOC_5_NAME: string (nullable = true)\n |-- LIGHTCAST_SECTORS: string (nullable = true)\n |-- LIGHTCAST_SECTORS_NAME: string (nullable = true)\n |-- NAICS_2022_2: integer (nullable = true)\n |-- NAICS_2022_2_NAME: string (nullable = true)\n |-- NAICS_2022_3: integer (nullable = true)\n |-- NAICS_2022_3_NAME: string (nullable = true)\n |-- NAICS_2022_4: integer (nullable = true)\n |-- NAICS_2022_4_NAME: string (nullable = true)\n |-- NAICS_2022_5: integer (nullable = true)\n |-- NAICS_2022_5_NAME: string (nullable = true)\n |-- NAICS_2022_6: integer (nullable = true)\n |-- NAICS_2022_6_NAME: string (nullable = true)\n\n+--------------------+-----------------+----------------------+----------+--------+---------+--------+--------------------+--------------------+--------------------+-----------+-------------------+--------------------+--------------------+---------------+----------------+--------+--------------------+-----------+-------------------+----------------+---------------------+-------------+-------------------+-------------+------------------+---------------+--------------------+--------------------+--------------------+-------------+------+-----------+----------------+-------------------+---------+-----------+--------------------+--------------------+-------------+------+--------------+-----+--------------------+-----+----------+---------------+--------------------+---------------+--------------------+------------+--------------------+------------+--------------------+------+--------------------+------+--------------------+------+--------------------+------+--------------------+------+--------------------+------------------+-------------------+--------------------+--------------------+--------------------+--------------------+-----------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+--------------------+----------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+--------------------+----------+--------------------+----------+---------------+----------+---------------+---------------+--------------------+--------------+--------------------+--------------------------+-------------------------------+--------------------+-------------------------+-----------------------------+----------------------------------+-----------------+----------------------+-----------------------+----------------------------+------------------+-----------------------+-------+--------------------+-------+--------------------+-------+---------------+-------+---------------+-----------------+----------------------+------------+--------------------+------------+--------------------+------------+--------------------+------------+--------------------+------------+--------------------+\n|                  ID|LAST_UPDATED_DATE|LAST_UPDATED_TIMESTAMP|DUPLICATES|  POSTED|  EXPIRED|DURATION|        SOURCE_TYPES|             SOURCES|                 URL|ACTIVE_URLS|ACTIVE_SOURCES_INFO|           TITLE_RAW|                BODY|MODELED_EXPIRED|MODELED_DURATION| COMPANY|        COMPANY_NAME|COMPANY_RAW|COMPANY_IS_STAFFING|EDUCATION_LEVELS|EDUCATION_LEVELS_NAME|MIN_EDULEVELS| MIN_EDULEVELS_NAME|MAX_EDULEVELS|MAX_EDULEVELS_NAME|EMPLOYMENT_TYPE|EMPLOYMENT_TYPE_NAME|MIN_YEARS_EXPERIENCE|MAX_YEARS_EXPERIENCE|IS_INTERNSHIP|SALARY|REMOTE_TYPE|REMOTE_TYPE_NAME|ORIGINAL_PAY_PERIOD|SALARY_TO|SALARY_FROM|            LOCATION|                CITY|    CITY_NAME|COUNTY|   COUNTY_NAME|  MSA|            MSA_NAME|STATE|STATE_NAME|COUNTY_OUTGOING|COUNTY_NAME_OUTGOING|COUNTY_INCOMING|COUNTY_NAME_INCOMING|MSA_OUTGOING|   MSA_NAME_OUTGOING|MSA_INCOMING|   MSA_NAME_INCOMING|NAICS2|         NAICS2_NAME|NAICS3|         NAICS3_NAME|NAICS4|         NAICS4_NAME|NAICS5|         NAICS5_NAME|NAICS6|         NAICS6_NAME|             TITLE|         TITLE_NAME|         TITLE_CLEAN|              SKILLS|         SKILLS_NAME|  SPECIALIZED_SKILLS|SPECIALIZED_SKILLS_NAME|      CERTIFICATIONS| CERTIFICATIONS_NAME|       COMMON_SKILLS|  COMMON_SKILLS_NAME|     SOFTWARE_SKILLS|SOFTWARE_SKILLS_NAME|      ONET|           ONET_NAME| ONET_2019|      ONET_2019_NAME|                CIP6|           CIP6_NAME|                CIP4|           CIP4_NAME|                CIP2|           CIP2_NAME|SOC_2021_2|     SOC_2021_2_NAME|SOC_2021_3|     SOC_2021_3_NAME|SOC_2021_4|SOC_2021_4_NAME|SOC_2021_5|SOC_2021_5_NAME|LOT_CAREER_AREA|LOT_CAREER_AREA_NAME|LOT_OCCUPATION| LOT_OCCUPATION_NAME|LOT_SPECIALIZED_OCCUPATION|LOT_SPECIALIZED_OCCUPATION_NAME|LOT_OCCUPATION_GROUP|LOT_OCCUPATION_GROUP_NAME|LOT_V6_SPECIALIZED_OCCUPATION|LOT_V6_SPECIALIZED_OCCUPATION_NAME|LOT_V6_OCCUPATION|LOT_V6_OCCUPATION_NAME|LOT_V6_OCCUPATION_GROUP|LOT_V6_OCCUPATION_GROUP_NAME|LOT_V6_CAREER_AREA|LOT_V6_CAREER_AREA_NAME|  SOC_2|          SOC_2_NAME|  SOC_3|          SOC_3_NAME|  SOC_4|     SOC_4_NAME|  SOC_5|     SOC_5_NAME|LIGHTCAST_SECTORS|LIGHTCAST_SECTORS_NAME|NAICS_2022_2|   NAICS_2022_2_NAME|NAICS_2022_3|   NAICS_2022_3_NAME|NAICS_2022_4|   NAICS_2022_4_NAME|NAICS_2022_5|   NAICS_2022_5_NAME|NAICS_2022_6|   NAICS_2022_6_NAME|\n+--------------------+-----------------+----------------------+----------+--------+---------+--------+--------------------+--------------------+--------------------+-----------+-------------------+--------------------+--------------------+---------------+----------------+--------+--------------------+-----------+-------------------+----------------+---------------------+-------------+-------------------+-------------+------------------+---------------+--------------------+--------------------+--------------------+-------------+------+-----------+----------------+-------------------+---------+-----------+--------------------+--------------------+-------------+------+--------------+-----+--------------------+-----+----------+---------------+--------------------+---------------+--------------------+------------+--------------------+------------+--------------------+------+--------------------+------+--------------------+------+--------------------+------+--------------------+------+--------------------+------------------+-------------------+--------------------+--------------------+--------------------+--------------------+-----------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+--------------------+----------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+--------------------+----------+--------------------+----------+---------------+----------+---------------+---------------+--------------------+--------------+--------------------+--------------------------+-------------------------------+--------------------+-------------------------+-----------------------------+----------------------------------+-----------------+----------------------+-----------------------+----------------------------+------------------+-----------------------+-------+--------------------+-------+--------------------+-------+---------------+-------+---------------+-----------------+----------------------+------------+--------------------+------------+--------------------+------------+--------------------+------------+--------------------+------------+--------------------+\n|1f57d95acf4dc67ed...|         9/6/2024|  2024-09-06 20:32:...|         0|6/2/2024| 6/8/2024|       6|   [\\n  \"Company\"\\n]|[\\n  \"brassring.c...|[\\n  \"https://sjo...|         []|               NULL|Enterprise Analys...|31-May-2024\\n\\nEn...|       6/8/2024|               6|  894731|          Murphy USA| Murphy USA|              false|       [\\n  2\\n]| [\\n  \"Bachelor's ...|            2|  Bachelor's degree|         NULL|              NULL|              1|Full-time (&gt; 32 h...|                   2|                   2|        false|  NULL|          0|          [None]|               NULL|     NULL|       NULL|{\\n  \"lat\": 33.20...|RWwgRG9yYWRvLCBBUg==|El Dorado, AR|  5139|     Union, AR|20980|       El Dorado, AR|    5|  Arkansas|           5139|           Union, AR|           5139|           Union, AR|       20980|       El Dorado, AR|       20980|       El Dorado, AR|    44|        Retail Trade|   441|Motor Vehicle and...|  4413|Automotive Parts,...| 44133|Automotive Parts ...|441330|Automotive Parts ...|ET29C073C03D1F86B4|Enterprise Analysts|enterprise analys...|[\\n  \"KS126DB6T06...|[\\n  \"Merchandisi...|[\\n  \"KS126DB6T06...|   [\\n  \"Merchandisi...|                  []|                  []|[\\n  \"KS126706DPF...|[\\n  \"Mathematics...|[\\n  \"KS440W865GC...|[\\n  \"SQL (Progra...|15-2051.01|Business Intellig...|15-2051.01|Business Intellig...|[\\n  \"45.0601\",\\n...|[\\n  \"Economics, ...|[\\n  \"45.06\",\\n  ...|[\\n  \"Economics\",...|[\\n  \"45\",\\n  \"27...|[\\n  \"Social Scie...|   15-0000|Computer and Math...|   15-2000|Mathematical Scie...|   15-2050|Data Scientists|   15-2051|Data Scientists|             23|Information Techn...|        231010|Business Intellig...|                  23101011|           General ERP Analy...|                2310|     Business Intellig...|                     23101011|              General ERP Analy...|           231010|  Business Intellig...|                   2310|        Business Intellig...|                23|   Information Techn...|15-0000|Computer and Math...|15-2000|Mathematical Scie...|15-2050|Data Scientists|15-2051|Data Scientists|        [\\n  7\\n]|  [\\n  \"Artificial ...|          44|        Retail Trade|         441|Motor Vehicle and...|        4413|Automotive Parts,...|       44133|Automotive Parts ...|      441330|Automotive Parts ...|\n|0cb072af26757b6c4...|         8/2/2024|  2024-08-02 17:08:...|         0|6/2/2024| 8/1/2024|    NULL| [\\n  \"Job Board\"\\n]| [\\n  \"maine.gov\"\\n]|[\\n  \"https://job...|         []|               NULL|Oracle Consultant...|Oracle Consultant...|       8/1/2024|            NULL|  133098|Smx Corporation L...|        SMX|               true|      [\\n  99\\n]| [\\n  \"No Educatio...|           99|No Education Listed|         NULL|              NULL|              1|Full-time (&gt; 32 h...|                   3|                   3|        false|  NULL|          1|          Remote|               NULL|     NULL|       NULL|{\\n  \"lat\": 44.31...|    QXVndXN0YSwgTUU=|  Augusta, ME| 23011|  Kennebec, ME|12300|Augusta-Watervill...|   23|     Maine|          23011|        Kennebec, ME|          23011|        Kennebec, ME|       12300|Augusta-Watervill...|       12300|Augusta-Watervill...|    56|Administrative an...|   561|Administrative an...|  5613| Employment Services| 56132|Temporary Help Se...|561320|Temporary Help Se...|ET21DDA63780A7DC09| Oracle Consultants|oracle consultant...|[\\n  \"KS122626T55...|[\\n  \"Procurement...|[\\n  \"KS122626T55...|   [\\n  \"Procurement...|                  []|                  []|                  []|                  []|[\\n  \"BGSBF3F508F...|[\\n  \"Oracle Busi...|15-2051.01|Business Intellig...|15-2051.01|Business Intellig...|                  []|                  []|                  []|                  []|                  []|                  []|   15-0000|Computer and Math...|   15-2000|Mathematical Scie...|   15-2050|Data Scientists|   15-2051|Data Scientists|             23|Information Techn...|        231010|Business Intellig...|                  23101012|           Oracle Consultant...|                2310|     Business Intellig...|                     23101012|              Oracle Consultant...|           231010|  Business Intellig...|                   2310|        Business Intellig...|                23|   Information Techn...|15-0000|Computer and Math...|15-2000|Mathematical Scie...|15-2050|Data Scientists|15-2051|Data Scientists|             NULL|                  NULL|          56|Administrative an...|         561|Administrative an...|        5613| Employment Services|       56132|Temporary Help Se...|      561320|Temporary Help Se...|\n|85318b12b3331fa49...|         9/6/2024|  2024-09-06 20:32:...|         1|6/2/2024| 7/7/2024|      35| [\\n  \"Job Board\"\\n]|[\\n  \"dejobs.org\"\\n]|[\\n  \"https://dej...|         []|               NULL|        Data Analyst|Taking care of pe...|      6/10/2024|               8|39063746|            Sedgwick|   Sedgwick|              false|       [\\n  2\\n]| [\\n  \"Bachelor's ...|            2|  Bachelor's degree|         NULL|              NULL|              1|Full-time (&gt; 32 h...|                   5|                NULL|        false|  NULL|          0|          [None]|               NULL|     NULL|       NULL|{\\n  \"lat\": 32.77...|    RGFsbGFzLCBUWA==|   Dallas, TX| 48113|    Dallas, TX|19100|Dallas-Fort Worth...|   48|     Texas|          48113|          Dallas, TX|          48113|          Dallas, TX|       19100|Dallas-Fort Worth...|       19100|Dallas-Fort Worth...|    52|Finance and Insur...|   524|Insurance Carrier...|  5242|Agencies, Brokera...| 52429|Other Insurance R...|524291|    Claims Adjusting|ET3037E0C947A02404|      Data Analysts|        data analyst|[\\n  \"KS1218W78FG...|[\\n  \"Management\"...|[\\n  \"ESF3939CE1F...|   [\\n  \"Exception R...|[\\n  \"KS683TN76T7...|[\\n  \"Security Cl...|[\\n  \"KS1218W78FG...|[\\n  \"Management\"...|[\\n  \"KS126HY6YLT...|[\\n  \"Microsoft O...|15-2051.01|Business Intellig...|15-2051.01|Business Intellig...|                  []|                  []|                  []|                  []|                  []|                  []|   15-0000|Computer and Math...|   15-2000|Mathematical Scie...|   15-2050|Data Scientists|   15-2051|Data Scientists|             23|Information Techn...|        231113|Data / Data Minin...|                  23111310|                   Data Analyst|                2311|     Data Analysis and...|                     23111310|                      Data Analyst|           231113|  Data / Data Minin...|                   2311|        Data Analysis and...|                23|   Information Techn...|15-0000|Computer and Math...|15-2000|Mathematical Scie...|15-2050|Data Scientists|15-2051|Data Scientists|             NULL|                  NULL|          52|Finance and Insur...|         524|Insurance Carrier...|        5242|Agencies, Brokera...|       52429|Other Insurance R...|      524291|    Claims Adjusting|\n|1b5c3941e54a1889e...|         9/6/2024|  2024-09-06 20:32:...|         1|6/2/2024|7/20/2024|      48| [\\n  \"Job Board\"\\n]|[\\n  \"disabledper...|[\\n  \"https://www...|         []|               NULL|Sr. Lead Data Mgm...|About this role:\\...|      6/12/2024|              10|37615159|         Wells Fargo|Wells Fargo|              false|      [\\n  99\\n]| [\\n  \"No Educatio...|           99|No Education Listed|         NULL|              NULL|              1|Full-time (&gt; 32 h...|                   3|                NULL|        false|  NULL|          0|          [None]|               NULL|     NULL|       NULL|{\\n  \"lat\": 33.44...|    UGhvZW5peCwgQVo=|  Phoenix, AZ|  4013|  Maricopa, AZ|38060|Phoenix-Mesa-Chan...|    4|   Arizona|           4013|        Maricopa, AZ|           4013|        Maricopa, AZ|       38060|Phoenix-Mesa-Chan...|       38060|Phoenix-Mesa-Chan...|    52|Finance and Insur...|   522|Credit Intermedia...|  5221|Depository Credit...| 52211|  Commercial Banking|522110|  Commercial Banking|ET2114E0404BA30075|Management Analysts|sr lead data mgmt...|[\\n  \"KS123QX62QY...|[\\n  \"Exit Strate...|[\\n  \"KS123QX62QY...|   [\\n  \"Exit Strate...|                  []|                  []|[\\n  \"KS7G6NP6R6L...|[\\n  \"Reliability...|[\\n  \"KS4409D76NW...|[\\n  \"SAS (Softwa...|15-2051.01|Business Intellig...|15-2051.01|Business Intellig...|                  []|                  []|                  []|                  []|                  []|                  []|   15-0000|Computer and Math...|   15-2000|Mathematical Scie...|   15-2050|Data Scientists|   15-2051|Data Scientists|             23|Information Techn...|        231113|Data / Data Minin...|                  23111310|                   Data Analyst|                2311|     Data Analysis and...|                     23111310|                      Data Analyst|           231113|  Data / Data Minin...|                   2311|        Data Analysis and...|                23|   Information Techn...|15-0000|Computer and Math...|15-2000|Mathematical Scie...|15-2050|Data Scientists|15-2051|Data Scientists|        [\\n  6\\n]|  [\\n  \"Data Privac...|          52|Finance and Insur...|         522|Credit Intermedia...|        5221|Depository Credit...|       52211|  Commercial Banking|      522110|  Commercial Banking|\n|cb5ca25f02bdf25c1...|        6/19/2024|   2024-06-19 07:00:00|         0|6/2/2024|6/17/2024|      15|[\\n  \"FreeJobBoar...|[\\n  \"craigslist....|[\\n  \"https://mod...|         []|               NULL|Comisiones de $10...|Comisiones de $10...|      6/17/2024|              15|       0|        Unclassified|      LH/GM|              false|      [\\n  99\\n]| [\\n  \"No Educatio...|           99|No Education Listed|         NULL|              NULL|              3|Part-time / full-...|                NULL|                NULL|        false| 92500|          0|          [None]|               year|   150000|      35000|{\\n  \"lat\": 37.63...|    TW9kZXN0bywgQ0E=|  Modesto, CA|  6099|Stanislaus, CA|33700|         Modesto, CA|    6|California|           6099|      Stanislaus, CA|           6099|      Stanislaus, CA|       33700|         Modesto, CA|       33700|         Modesto, CA|    99|Unclassified Indu...|   999|Unclassified Indu...|  9999|Unclassified Indu...| 99999|Unclassified Indu...|999999|Unclassified Indu...|ET0000000000000000|       Unclassified|comisiones de por...|                  []|                  []|                  []|                     []|                  []|                  []|                  []|                  []|                  []|                  []|15-2051.01|Business Intellig...|15-2051.01|Business Intellig...|                  []|                  []|                  []|                  []|                  []|                  []|   15-0000|Computer and Math...|   15-2000|Mathematical Scie...|   15-2050|Data Scientists|   15-2051|Data Scientists|             23|Information Techn...|        231010|Business Intellig...|                  23101012|           Oracle Consultant...|                2310|     Business Intellig...|                     23101012|              Oracle Consultant...|           231010|  Business Intellig...|                   2310|        Business Intellig...|                23|   Information Techn...|15-0000|Computer and Math...|15-2000|Mathematical Scie...|15-2050|Data Scientists|15-2051|Data Scientists|             NULL|                  NULL|          99|Unclassified Indu...|         999|Unclassified Indu...|        9999|Unclassified Indu...|       99999|Unclassified Indu...|      999999|Unclassified Indu...|\n+--------------------+-----------------+----------------------+----------+--------+---------+--------+--------------------+--------------------+--------------------+-----------+-------------------+--------------------+--------------------+---------------+----------------+--------+--------------------+-----------+-------------------+----------------+---------------------+-------------+-------------------+-------------+------------------+---------------+--------------------+--------------------+--------------------+-------------+------+-----------+----------------+-------------------+---------+-----------+--------------------+--------------------+-------------+------+--------------+-----+--------------------+-----+----------+---------------+--------------------+---------------+--------------------+------------+--------------------+------------+--------------------+------+--------------------+------+--------------------+------+--------------------+------+--------------------+------+--------------------+------------------+-------------------+--------------------+--------------------+--------------------+--------------------+-----------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+--------------------+----------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+--------------------+----------+--------------------+----------+---------------+----------+---------------+---------------+--------------------+--------------+--------------------+--------------------------+-------------------------------+--------------------+-------------------------+-----------------------------+----------------------------------+-----------------+----------------------+-----------------------+----------------------------+------------------+-----------------------+-------+--------------------+-------+--------------------+-------+---------------+-------+---------------+-----------------+----------------------+------------+--------------------+------------+--------------------+------------+--------------------+------------+--------------------+------------+--------------------+\nonly showing top 5 rows\n\n\n\n\n## Listing Columns So We Can Reference them in Visuals\n\nimport pandas as pd\ndf = pd.read_csv(\"./data/lightcast_job_postings.csv\")\nprint(df.columns.tolist())\n\n/tmp/ipykernel_2561/3265774581.py:4: DtypeWarning:\n\nColumns (19,30) have mixed types. Specify dtype option on import or set low_memory=False.\n\n\n\n['ID', 'LAST_UPDATED_DATE', 'LAST_UPDATED_TIMESTAMP', 'DUPLICATES', 'POSTED', 'EXPIRED', 'DURATION', 'SOURCE_TYPES', 'SOURCES', 'URL', 'ACTIVE_URLS', 'ACTIVE_SOURCES_INFO', 'TITLE_RAW', 'BODY', 'MODELED_EXPIRED', 'MODELED_DURATION', 'COMPANY', 'COMPANY_NAME', 'COMPANY_RAW', 'COMPANY_IS_STAFFING', 'EDUCATION_LEVELS', 'EDUCATION_LEVELS_NAME', 'MIN_EDULEVELS', 'MIN_EDULEVELS_NAME', 'MAX_EDULEVELS', 'MAX_EDULEVELS_NAME', 'EMPLOYMENT_TYPE', 'EMPLOYMENT_TYPE_NAME', 'MIN_YEARS_EXPERIENCE', 'MAX_YEARS_EXPERIENCE', 'IS_INTERNSHIP', 'SALARY', 'REMOTE_TYPE', 'REMOTE_TYPE_NAME', 'ORIGINAL_PAY_PERIOD', 'SALARY_TO', 'SALARY_FROM', 'LOCATION', 'CITY', 'CITY_NAME', 'COUNTY', 'COUNTY_NAME', 'MSA', 'MSA_NAME', 'STATE', 'STATE_NAME', 'COUNTY_OUTGOING', 'COUNTY_NAME_OUTGOING', 'COUNTY_INCOMING', 'COUNTY_NAME_INCOMING', 'MSA_OUTGOING', 'MSA_NAME_OUTGOING', 'MSA_INCOMING', 'MSA_NAME_INCOMING', 'NAICS2', 'NAICS2_NAME', 'NAICS3', 'NAICS3_NAME', 'NAICS4', 'NAICS4_NAME', 'NAICS5', 'NAICS5_NAME', 'NAICS6', 'NAICS6_NAME', 'TITLE', 'TITLE_NAME', 'TITLE_CLEAN', 'SKILLS', 'SKILLS_NAME', 'SPECIALIZED_SKILLS', 'SPECIALIZED_SKILLS_NAME', 'CERTIFICATIONS', 'CERTIFICATIONS_NAME', 'COMMON_SKILLS', 'COMMON_SKILLS_NAME', 'SOFTWARE_SKILLS', 'SOFTWARE_SKILLS_NAME', 'ONET', 'ONET_NAME', 'ONET_2019', 'ONET_2019_NAME', 'CIP6', 'CIP6_NAME', 'CIP4', 'CIP4_NAME', 'CIP2', 'CIP2_NAME', 'SOC_2021_2', 'SOC_2021_2_NAME', 'SOC_2021_3', 'SOC_2021_3_NAME', 'SOC_2021_4', 'SOC_2021_4_NAME', 'SOC_2021_5', 'SOC_2021_5_NAME', 'LOT_CAREER_AREA', 'LOT_CAREER_AREA_NAME', 'LOT_OCCUPATION', 'LOT_OCCUPATION_NAME', 'LOT_SPECIALIZED_OCCUPATION', 'LOT_SPECIALIZED_OCCUPATION_NAME', 'LOT_OCCUPATION_GROUP', 'LOT_OCCUPATION_GROUP_NAME', 'LOT_V6_SPECIALIZED_OCCUPATION', 'LOT_V6_SPECIALIZED_OCCUPATION_NAME', 'LOT_V6_OCCUPATION', 'LOT_V6_OCCUPATION_NAME', 'LOT_V6_OCCUPATION_GROUP', 'LOT_V6_OCCUPATION_GROUP_NAME', 'LOT_V6_CAREER_AREA', 'LOT_V6_CAREER_AREA_NAME', 'SOC_2', 'SOC_2_NAME', 'SOC_3', 'SOC_3_NAME', 'SOC_4', 'SOC_4_NAME', 'SOC_5', 'SOC_5_NAME', 'LIGHTCAST_SECTORS', 'LIGHTCAST_SECTORS_NAME', 'NAICS_2022_2', 'NAICS_2022_2_NAME', 'NAICS_2022_3', 'NAICS_2022_3_NAME', 'NAICS_2022_4', 'NAICS_2022_4_NAME', 'NAICS_2022_5', 'NAICS_2022_5_NAME', 'NAICS_2022_6', 'NAICS_2022_6_NAME']\n\n\n\nimport pandas as pd\n\ndf = pd.read_csv(\"./data/lightcast_job_postings.csv\")\n\ncolumns_to_drop = [\n    \"ID\", \"URL\", \"ACTIVE_URLS\", \"DUPLICATES\", \"LAST_UPDATED_TIMESTAMP\",\n    \"NAICS2\", \"NAICS3\", \"NAICS4\", \"NAICS5\", \"NAICS6\",\n    \"SOC_2\", \"SOC_3\", \"SOC_5\"\n]\n\ndf.drop(columns=columns_to_drop, inplace=True)\n\n/tmp/ipykernel_2561/304705447.py:3: DtypeWarning:\n\nColumns (19,30) have mixed types. Specify dtype option on import or set low_memory=False.\n\n\n\n\nprint(df.columns.tolist())\n\n['ID', 'LAST_UPDATED_DATE', 'LAST_UPDATED_TIMESTAMP', 'DUPLICATES', 'POSTED', 'EXPIRED', 'DURATION', 'SOURCE_TYPES', 'SOURCES', 'URL', 'ACTIVE_URLS', 'ACTIVE_SOURCES_INFO', 'TITLE_RAW', 'BODY', 'MODELED_EXPIRED', 'MODELED_DURATION', 'COMPANY', 'COMPANY_NAME', 'COMPANY_RAW', 'COMPANY_IS_STAFFING', 'EDUCATION_LEVELS', 'EDUCATION_LEVELS_NAME', 'MIN_EDULEVELS', 'MIN_EDULEVELS_NAME', 'MAX_EDULEVELS', 'MAX_EDULEVELS_NAME', 'EMPLOYMENT_TYPE', 'EMPLOYMENT_TYPE_NAME', 'MIN_YEARS_EXPERIENCE', 'MAX_YEARS_EXPERIENCE', 'IS_INTERNSHIP', 'SALARY', 'REMOTE_TYPE', 'REMOTE_TYPE_NAME', 'ORIGINAL_PAY_PERIOD', 'SALARY_TO', 'SALARY_FROM', 'LOCATION', 'CITY', 'CITY_NAME', 'COUNTY', 'COUNTY_NAME', 'MSA', 'MSA_NAME', 'STATE', 'STATE_NAME', 'COUNTY_OUTGOING', 'COUNTY_NAME_OUTGOING', 'COUNTY_INCOMING', 'COUNTY_NAME_INCOMING', 'MSA_OUTGOING', 'MSA_NAME_OUTGOING', 'MSA_INCOMING', 'MSA_NAME_INCOMING', 'NAICS2', 'NAICS2_NAME', 'NAICS3', 'NAICS3_NAME', 'NAICS4', 'NAICS4_NAME', 'NAICS5', 'NAICS5_NAME', 'NAICS6', 'NAICS6_NAME', 'TITLE', 'TITLE_NAME', 'TITLE_CLEAN', 'SKILLS', 'SKILLS_NAME', 'SPECIALIZED_SKILLS', 'SPECIALIZED_SKILLS_NAME', 'CERTIFICATIONS', 'CERTIFICATIONS_NAME', 'COMMON_SKILLS', 'COMMON_SKILLS_NAME', 'SOFTWARE_SKILLS', 'SOFTWARE_SKILLS_NAME', 'ONET', 'ONET_NAME', 'ONET_2019', 'ONET_2019_NAME', 'CIP6', 'CIP6_NAME', 'CIP4', 'CIP4_NAME', 'CIP2', 'CIP2_NAME', 'SOC_2021_2', 'SOC_2021_2_NAME', 'SOC_2021_3', 'SOC_2021_3_NAME', 'SOC_2021_4', 'SOC_2021_4_NAME', 'SOC_2021_5', 'SOC_2021_5_NAME', 'LOT_CAREER_AREA', 'LOT_CAREER_AREA_NAME', 'LOT_OCCUPATION', 'LOT_OCCUPATION_NAME', 'LOT_SPECIALIZED_OCCUPATION', 'LOT_SPECIALIZED_OCCUPATION_NAME', 'LOT_OCCUPATION_GROUP', 'LOT_OCCUPATION_GROUP_NAME', 'LOT_V6_SPECIALIZED_OCCUPATION', 'LOT_V6_SPECIALIZED_OCCUPATION_NAME', 'LOT_V6_OCCUPATION', 'LOT_V6_OCCUPATION_NAME', 'LOT_V6_OCCUPATION_GROUP', 'LOT_V6_OCCUPATION_GROUP_NAME', 'LOT_V6_CAREER_AREA', 'LOT_V6_CAREER_AREA_NAME', 'SOC_2', 'SOC_2_NAME', 'SOC_3', 'SOC_3_NAME', 'SOC_4', 'SOC_4_NAME', 'SOC_5', 'SOC_5_NAME', 'LIGHTCAST_SECTORS', 'LIGHTCAST_SECTORS_NAME', 'NAICS_2022_2', 'NAICS_2022_2_NAME', 'NAICS_2022_3', 'NAICS_2022_3_NAME', 'NAICS_2022_4', 'NAICS_2022_4_NAME', 'NAICS_2022_5', 'NAICS_2022_5_NAME', 'NAICS_2022_6', 'NAICS_2022_6_NAME']\n\n\n\n!pip install missingno\n\nRequirement already satisfied: missingno in ./.venv/lib/python3.12/site-packages (0.5.2)\nRequirement already satisfied: numpy in ./.venv/lib/python3.12/site-packages (from missingno) (2.2.6)\nRequirement already satisfied: matplotlib in ./.venv/lib/python3.12/site-packages (from missingno) (3.10.3)\nRequirement already satisfied: scipy in ./.venv/lib/python3.12/site-packages (from missingno) (1.15.3)\nRequirement already satisfied: seaborn in ./.venv/lib/python3.12/site-packages (from missingno) (0.13.2)\nRequirement already satisfied: contourpy&gt;=1.0.1 in ./.venv/lib/python3.12/site-packages (from matplotlib-&gt;missingno) (1.3.2)\nRequirement already satisfied: cycler&gt;=0.10 in ./.venv/lib/python3.12/site-packages (from matplotlib-&gt;missingno) (0.12.1)\nRequirement already satisfied: fonttools&gt;=4.22.0 in ./.venv/lib/python3.12/site-packages (from matplotlib-&gt;missingno) (4.58.0)\nRequirement already satisfied: kiwisolver&gt;=1.3.1 in ./.venv/lib/python3.12/site-packages (from matplotlib-&gt;missingno) (1.4.8)\nRequirement already satisfied: packaging&gt;=20.0 in ./.venv/lib/python3.12/site-packages (from matplotlib-&gt;missingno) (25.0)\nRequirement already satisfied: pillow&gt;=8 in ./.venv/lib/python3.12/site-packages (from matplotlib-&gt;missingno) (11.2.1)\nRequirement already satisfied: pyparsing&gt;=2.3.1 in ./.venv/lib/python3.12/site-packages (from matplotlib-&gt;missingno) (3.2.3)\nRequirement already satisfied: python-dateutil&gt;=2.7 in ./.venv/lib/python3.12/site-packages (from matplotlib-&gt;missingno) (2.9.0.post0)\nRequirement already satisfied: pandas&gt;=1.2 in ./.venv/lib/python3.12/site-packages (from seaborn-&gt;missingno) (2.2.3)\nRequirement already satisfied: pytz&gt;=2020.1 in ./.venv/lib/python3.12/site-packages (from pandas&gt;=1.2-&gt;seaborn-&gt;missingno) (2025.2)\nRequirement already satisfied: tzdata&gt;=2022.7 in ./.venv/lib/python3.12/site-packages (from pandas&gt;=1.2-&gt;seaborn-&gt;missingno) (2025.2)\nRequirement already satisfied: six&gt;=1.5 in ./.venv/lib/python3.12/site-packages (from python-dateutil&gt;=2.7-&gt;matplotlib-&gt;missingno) (1.17.0)\n\n\n\nimport missingno as msno\nimport matplotlib.pyplot as plt\n# Visualize missing values\nmsno.heatmap(df)\nplt.title(\"Missing Values Heatmap\")\nplt.show()\n\n# Drop columns with &gt;50% missing values\ndf.dropna(thresh=len(df) * 0.5, axis=1, inplace=True)\n\n# Fill only the columns you actually have\nif 'Industry' in df.columns:\n    df[\"Industry\"].fillna(\"Unknown\", inplace=True)\n    df[\"Salary\"].fillna(df[\"Salary\"].median(), inplace=True)\n\n\n\n\n\n\n\n\n\ndf = df.drop_duplicates(subset=[\"TITLE\", \"COMPANY\", \"LOCATION\", \"POSTED\"], keep=\"first\")\n\n\ndf = df[df['NAICS_2022_2_NAME'] != 'Unclassified Industry']\n\n\ndf['REMOTE_TYPE_NAME'] = df['REMOTE_TYPE_NAME'].replace('[None]', 'Unknown')\n\n\n\n\nimport pandas as pd\nimport plotly.express as px\n\n# Sample data setup (replace this with your actual dataframe)\ndata = {\n    'Industry': [\n        'Wholesale Trade', 'Retail Trade', 'Real Estate and Rental and Leasing',\n        'Professional, Scientific, and Technical Services', 'Manufacturing',\n        'Information', 'Health Care and Social Assistance',\n        'Finance and Insurance', 'Educational Services',\n        'Administrative and Support and Waste Management and Remediation Services'\n    ],\n    'Flexible Remote': [87.8, 94.4, 97.6, 92.2, 89.7, 95.8, 92.1, 94.8, 89.0, 94.8],\n    'Onsite': [12.2, 5.6, 2.4, 7.8, 10.3, 4.2, 7.9, 5.2, 11.0, 5.2]\n}\n\ndf = pd.DataFrame(data)\n\n# Melt the data for Plotly\ndf_melted = df.melt(id_vars='Industry', value_vars=['Flexible Remote', 'Onsite'],\n                    var_name='Remote Type', value_name='Percentage')\n\n# Sort industries by Flexible Remote % descending\ndf['SortKey'] = df['Flexible Remote']\ndf = df.sort_values(by='SortKey', ascending=False)\ndf_melted['Industry'] = pd.Categorical(df_melted['Industry'], categories=df['Industry'], ordered=True)\n\n# Plot\nfig = px.bar(\n    df_melted,\n    x=\"Percentage\",\n    y=\"Industry\",\n    color=\"Remote Type\",\n    orientation=\"h\",\n    text=\"Percentage\",\n    color_discrete_map={\"Flexible Remote\": \"#636EFA\", \"Onsite\": \"#EF553B\"},\n    title=\"Remote Job Distribution by Industry (Top 10 Industries)\"\n)\n\n# Clean layout, shift bars left\nfig.update_layout(\n    xaxis_title=\"Percentage of Jobs\",\n    yaxis_title=\"\",\n    xaxis=dict(tickformat=\".0f\"),\n    legend_title=\"Remote Type\",\n    barmode='stack',\n    margin=dict(l=10, r=10, t=60, b=40),  # Reduce margins\n    height=500\n)\n\n# Format labels\nfig.update_traces(texttemplate='%{text:.1f}%', textposition='inside')\n\nfig.show()\n\n\n\n\n\n\n\n\n        \n        \n        \n\n\n                                                    \n\n\n\nimport pandas as pd\nfrom IPython.display import display\n# 1. Load the dataset and parse dates\ndf = pd.read_csv(\"./data/lightcast_job_postings.csv\", parse_dates=[\"POSTED\", \"EXPIRED\"])\n# Calculate DURATION in days\ndf['DURATION'] = (df['EXPIRED'] - df['POSTED']).dt.days\n# Extract POSTED month\ndf['POSTED_MONTH'] = df['POSTED'].dt.to_period(\"M\")\n\n/tmp/ipykernel_2561/784347523.py:4: DtypeWarning:\n\nColumns (19,30) have mixed types. Specify dtype option on import or set low_memory=False.\n\n\n\n\n# Define AI and non-AI impacted NAICS codes\nai_impacted_naics = [31, 32, 33, 42, 44, 45, 51, 52, 54, 55, 56]\nnon_ai_impacted_naics = [11, 21, 22, 23, 48, 49, 61, 62, 71, 72]\n\n\n# Create IS_AI_JOB flag\ndf['IS_AI_JOB'] = df['NAICS_2022_2'].apply(lambda x: 1 if pd.notna(x) and x in ai_impacted_naics else 0)\n\n# Remove rows with missing STATE_NAME or POSTED_MONTH\ndf = df[df['STATE_NAME'].notna() & df['POSTED_MONTH'].notna()]\n\n# Group by POSTED_MONTH, STATE_NAME, IS_AI_JOB to count jobs\njob_counts = (\n    df.groupby(['POSTED_MONTH', 'STATE_NAME', 'IS_AI_JOB'])\n      .size()\n      .reset_index(name='JOB_COUNT')\n)\n\n\n# Pivot to put months as rows, states as columns\npivot_df = job_counts.pivot_table(index=['STATE_NAME', 'IS_AI_JOB'], \n                                   columns='POSTED_MONTH', \n                                   values='JOB_COUNT', \n                                   fill_value=0)\n\n# Calculate % growth from first to last month\nfirst_month = pivot_df.columns[0]\nlast_month = pivot_df.columns[-1]\npivot_df['PCT_GROWTH'] = ((pivot_df[last_month] - pivot_df[first_month]) / \n                          pivot_df[first_month].replace(0, pd.NA)) * 100\n\n# Drop rows with undefined % growth (divide by zero)\npivot_df = pivot_df.dropna(subset=['PCT_GROWTH'])\n\n# Reset index for sorting\npivot_df = pivot_df.reset_index()\n\n\n# Get top 10 states by % growth\ntop_ai = pivot_df[pivot_df['IS_AI_JOB'] == 1].sort_values('PCT_GROWTH', ascending=False).head(10)\ntop_non_ai = pivot_df[pivot_df['IS_AI_JOB'] == 0].sort_values('PCT_GROWTH', ascending=False).head(10)\n\n# Combine and label\ntop_combined = pd.concat([\n    top_ai.assign(JOB_TYPE='AI'),\n    top_non_ai.assign(JOB_TYPE='Non-AI')\n])\n\n# Display \ndisplay(top_combined[['STATE_NAME', 'IS_AI_JOB', 'PCT_GROWTH', 'JOB_TYPE']])\n\n\n\n\n\n\n\nPOSTED_MONTH\nSTATE_NAME\nIS_AI_JOB\nPCT_GROWTH\nJOB_TYPE\n\n\n\n\n101\nWyoming\n1\n380.000000\nAI\n\n\n97\nWest Virginia\n1\n380.000000\nAI\n\n\n81\nSouth Dakota\n1\n175.000000\nAI\n\n\n21\nHawaii\n1\n75.000000\nAI\n\n\n67\nNorth Dakota\n1\n64.285714\nAI\n\n\n61\nNew Mexico\n1\n56.000000\nAI\n\n\n73\nOregon\n1\n54.716981\nAI\n\n\n41\nMassachusetts\n1\n40.074906\nAI\n\n\n95\nWashington, D.C. (District of Columbia)\n1\n36.363636\nAI\n\n\n53\nNebraska\n1\n36.065574\nAI\n\n\n66\nNorth Dakota\n0\n275.000000\nNon-AI\n\n\n88\nVermont\n0\n225.000000\nNon-AI\n\n\n96\nWest Virginia\n0\n130.000000\nNon-AI\n\n\n52\nNebraska\n0\n100.000000\nNon-AI\n\n\n72\nOregon\n0\n100.000000\nNon-AI\n\n\n2\nAlaska\n0\n92.307692\nNon-AI\n\n\n32\nKentucky\n0\n53.125000\nNon-AI\n\n\n94\nWashington, D.C. (District of Columbia)\n0\n40.000000\nNon-AI\n\n\n48\nMissouri\n0\n37.931034\nNon-AI\n\n\n60\nNew Mexico\n0\n36.842105\nNon-AI\n\n\n\n\n\n\n\n\ndef label_ai_impact(naics):\n    try:\n        code = int(naics)\n        if code in ai_impacted_naics:\n            return \"AI-Impacted\"\n        elif code in non_ai_impacted_naics:\n            return \"Non-AI-Impacted\"\n        else:\n            return \"Unclassified\"\n    except:\n        return \"Unclassified\"\n\n\ndf['AI_IMPACTED'] = df['NAICS_2022_2'].apply(label_ai_impact)\n# Filter only AI and Non-AI impacted\ndf = df[df[\"AI_IMPACTED\"].isin([\"AI-Impacted\", \"Non-AI-Impacted\"])]\n\n# Now split the data\nai_df = df[df[\"AI_IMPACTED\"] == \"AI-Impacted\"][\n    [\"STATE_NAME\", \"NAICS_2022_2\", \"NAICS_2022_2_NAME\", \"LOT_SPECIALIZED_OCCUPATION_NAME\"]\n]\n\nnon_ai_df = df[df[\"AI_IMPACTED\"] == \"Non-AI-Impacted\"][\n    [\"STATE_NAME\", \"NAICS_2022_2\", \"NAICS_2022_2_NAME\", \"LOT_SPECIALIZED_OCCUPATION_NAME\"]\n]\n\n\nfrom IPython.display import display\n\nprint(\"AI-Impacted Industries:\")\ndisplay(ai_df)\n\nprint(\"\\nNon-AI-Impacted Industries:\")\ndisplay(non_ai_df)\n\nAI-Impacted Industries:\n\n\n\n\n\n\n\n\n\nSTATE_NAME\nNAICS_2022_2\nNAICS_2022_2_NAME\nLOT_SPECIALIZED_OCCUPATION_NAME\n\n\n\n\n0\nArkansas\n44.0\nRetail Trade\nGeneral ERP Analyst / Consultant\n\n\n1\nMaine\n56.0\nAdministrative and Support and Waste Managemen...\nOracle Consultant / Analyst\n\n\n2\nTexas\n52.0\nFinance and Insurance\nData Analyst\n\n\n3\nArizona\n52.0\nFinance and Insurance\nData Analyst\n\n\n5\nArkansas\n51.0\nInformation\nData Analyst\n\n\n...\n...\n...\n...\n...\n\n\n72493\nVirginia\n54.0\nProfessional, Scientific, and Technical Services\nData Analyst\n\n\n72494\nMassachusetts\n51.0\nInformation\nEnterprise Architect\n\n\n72495\nMichigan\n56.0\nAdministrative and Support and Waste Managemen...\nData Analyst\n\n\n72496\nMaine\n51.0\nInformation\nData Analyst\n\n\n72497\nTexas\n54.0\nProfessional, Scientific, and Technical Services\nOracle Consultant / Analyst\n\n\n\n\n49905 rows × 4 columns\n\n\n\n\nNon-AI-Impacted Industries:\n\n\n\n\n\n\n\n\n\nSTATE_NAME\nNAICS_2022_2\nNAICS_2022_2_NAME\nLOT_SPECIALIZED_OCCUPATION_NAME\n\n\n\n\n15\nMassachusetts\n61.0\nEducational Services\nData Analyst\n\n\n18\nAlabama\n62.0\nHealth Care and Social Assistance\nEnterprise Architect\n\n\n37\nVirginia\n62.0\nHealth Care and Social Assistance\nData Analyst\n\n\n77\nOhio\n23.0\nConstruction\nEnterprise Architect\n\n\n94\nTexas\n61.0\nEducational Services\nBusiness Analyst (General)\n\n\n...\n...\n...\n...\n...\n\n\n72450\nOklahoma\n48.0\nTransportation and Warehousing\nFinancial Data Analyst\n\n\n72451\nSouth Carolina\n62.0\nHealth Care and Social Assistance\nData Analyst\n\n\n72460\nCalifornia\n11.0\nAgriculture, Forestry, Fishing and Hunting\nData Analyst\n\n\n72479\nWyoming\n61.0\nEducational Services\nData Analyst\n\n\n72489\nTexas\n22.0\nUtilities\nSAP Analyst / Admin\n\n\n\n\n7627 rows × 4 columns\n\n\n\n\n# Step 1: Count total jobs by state\ntotal_jobs_by_state = df.groupby('STATE_NAME').size().rename('Total_Jobs')\n\n\n# Step 2: Count AI-impacted jobs by state\nai_jobs_by_state = df[df['AI_IMPACTED'] == 'AI-Impacted'].groupby('STATE_NAME').size().rename('AI_Impacted_Jobs')\n# Step 3: Merge the two counts into a single DataFrame\nai_impact_summary = pd.concat([total_jobs_by_state, ai_jobs_by_state], axis=1).fillna(0)\n\n\n# Step 4: Calculate percentage of AI-impacted jobs\nai_impact_summary['AI_Impact_Percentage'] = (ai_impact_summary['AI_Impacted_Jobs'] / ai_impact_summary['Total_Jobs']) * 100\n\n\n# Step 5: Sort states by highest percentage\nai_impact_summary_sorted = ai_impact_summary.sort_values(by='AI_Impact_Percentage', ascending=False)\n\n\n# Step 6: Display the top 10 states (or all if you prefer)\nfrom IPython.display import display\ndisplay(ai_impact_summary_sorted.head(10))\n\n\n\n\n\n\n\n\nTotal_Jobs\nAI_Impacted_Jobs\nAI_Impact_Percentage\n\n\nSTATE_NAME\n\n\n\n\n\n\n\nNew Jersey\n2156\n1976\n91.651206\n\n\nVermont\n201\n183\n91.044776\n\n\nIdaho\n399\n361\n90.476190\n\n\nNorth Carolina\n2225\n2013\n90.471910\n\n\nConnecticut\n723\n654\n90.456432\n\n\nHawaii\n183\n165\n90.163934\n\n\nWashington, D.C. (District of Columbia)\n933\n839\n89.924973\n\n\nWisconsin\n852\n766\n89.906103\n\n\nIllinois\n2802\n2515\n89.757316\n\n\nVirginia\n2919\n2619\n89.722508\n\n\n\n\n\n\n\n\n# Step 1: Clean and convert date columns\ndf = df[df['NAICS_2022_2_NAME'] != 'Unclassified Industry']\ndf['POSTED'] = pd.to_datetime(df['POSTED'], errors='coerce')\ndf['EXPIRED'] = pd.to_datetime(df['EXPIRED'], errors='coerce')\n\n# Drop rows with missing POSTED or EXPIRED dates\ndf = df.dropna(subset=['POSTED', 'EXPIRED'])\n\n\nimport plotly.express as px\n\n# Count postings per industry\nindustry_counts = df['NAICS2_NAME'].value_counts().reset_index()\nindustry_counts.columns = ['NAICS2_NAME', 'count']\n\n# Sort values for better readability\nindustry_counts = industry_counts.sort_values(by='count', ascending=True)\n\n# Horizontal bar plot\nfig = px.bar(\n    industry_counts,\n    x='count',\n    y='NAICS2_NAME',\n    orientation='h',\n    title='Job Postings by Industry',\n    labels={'NAICS2_NAME': 'Industry', 'count': 'Number of Postings'},\n    color='count',\n    color_continuous_scale='Blues'\n)\n\n# Clean layout\nfig.update_layout(\n    yaxis_title='Industry',\n    xaxis_title='Number of Postings',\n    title_font_size=20,\n    plot_bgcolor='white',\n    xaxis=dict(showgrid=True),\n    yaxis=dict(showgrid=False)\n)\n\nfig.show()\n\n        \n        \n        \n\n\n                                                    \n\n\n\n# Extract month from POSTED and EXPIRED\ndf['POSTED_MONTH'] = df['POSTED'].dt.to_period('M').astype(str)\ndf['EXPIRED_MONTH'] = df['EXPIRED'].dt.to_period('M').astype(str)\n\n\n# Step 2: Define AI and non-AI industry codes using NAICS 2-digit level\nai_impacted_naics = [31, 32, 33, 42, 44, 45, 51, 52, 54, 55, 56]\nnon_ai_impacted_naics = [11, 21, 22, 23, 48, 49, 61, 62, 71, 72]\ndef label_ai(naics):\n    try:\n        code = int(naics)\n        if code in ai_naics:\n            return \"AI-Impacted\"\n        elif code in non_ai_naics:\n            return \"Non-AI-Impacted\"\n        else:\n            return \"Unclassified\"\n    except:\n        return \"Unclassified\"\n    df['AI_IMPACTED'] = df['NAICS_2022_2'].apply(label_ai)\n    df = df[df['AI_IMPACTED'] != 'Unclassified']\n\n\n# Extract posting month\ndf['POSTED_MONTH'] = df['POSTED'].dt.to_period('M')\n\n# Count jobs by month, state, and AI impact\nmonthly_counts = (\n    df.groupby(['STATE_NAME', 'POSTED_MONTH', 'AI_IMPACTED'])\n    .size()\n    .reset_index(name='Job_Count')\n)\n\n\n\n# Pivot table to split AI vs Non-AI job counts\npivoted = monthly_counts.pivot_table(\n    index=['STATE_NAME', 'POSTED_MONTH'],\n    columns='AI_IMPACTED',\n    values='Job_Count',\n    fill_value=0\n).reset_index()\n# Sort by month for each state\npivoted.sort_values(by=['STATE_NAME', 'POSTED_MONTH'], inplace=True)\n\n\n\n# Step 6: Sort and calculate percent growth\npivoted.sort_values(['STATE_NAME', 'POSTED_MONTH'], inplace=True)\npivoted['AI_Growth'] = pivoted.groupby('STATE_NAME')['AI-Impacted'].pct_change() * 100\npivoted['Non_AI_Growth'] = pivoted.groupby('STATE_NAME')['Non-AI-Impacted'].pct_change() * 100\n\n# Drop rows with NaN (typically the first month per state)\npivoted.dropna(subset=['AI_Growth', 'Non_AI_Growth'], inplace=True)\n\n\n# Step 7: Average monthly growth by state\naverage_growth = pivoted.groupby('STATE_NAME')[['AI_Growth', 'Non_AI_Growth']].mean().reset_index()\nprint(average_growth)\n\nAI_IMPACTED                               STATE_NAME   AI_Growth  \\\n0                                            Alabama   -1.030391   \n1                                             Alaska    0.474691   \n2                                            Arizona   -0.396808   \n3                                           Arkansas   -6.340944   \n4                                         California   -7.115259   \n5                                           Colorado   -3.534986   \n6                                        Connecticut  -10.133298   \n7                                           Delaware  -10.990546   \n8                                            Florida   -9.705992   \n9                                            Georgia  -15.220526   \n10                                            Hawaii   70.988394   \n11                                             Idaho  -16.914886   \n12                                          Illinois  -17.089139   \n13                                           Indiana   -0.969177   \n14                                              Iowa   -9.540767   \n15                                            Kansas   -6.636718   \n16                                          Kentucky   10.591566   \n17                                         Louisiana    8.497502   \n18                                             Maine   -9.323389   \n19                                          Maryland  -14.177059   \n20                                     Massachusetts   -3.369591   \n21                                          Michigan  -13.326328   \n22                                         Minnesota   -5.627136   \n23                                       Mississippi   28.334651   \n24                                          Missouri  -14.850411   \n25                                           Montana   25.160256   \n26                                          Nebraska   10.707044   \n27                                            Nevada  -10.497371   \n28                                     New Hampshire    4.255144   \n29                                        New Jersey  -11.443245   \n30                                        New Mexico   10.431647   \n31                                          New York  -10.012403   \n32                                    North Carolina   -8.164973   \n33                                      North Dakota   12.428143   \n34                                              Ohio   -8.703213   \n35                                          Oklahoma    3.762787   \n36                                            Oregon    5.138959   \n37                                      Pennsylvania   -9.312598   \n38                                      Rhode Island    3.863502   \n39                                    South Carolina   -4.634607   \n40                                      South Dakota   30.021078   \n41                                         Tennessee  -10.719712   \n42                                             Texas   -9.760556   \n43                                              Utah   10.119048   \n44                                           Vermont    5.855271   \n45                                          Virginia   -9.747373   \n46                                        Washington   -7.818786   \n47           Washington, D.C. (District of Columbia)   -2.999583   \n48                                     West Virginia   99.738820   \n49                                         Wisconsin   -7.330027   \n50                                           Wyoming  135.099638   \n\nAI_IMPACTED  Non_AI_Growth  \n0                 0.127262  \n1                59.226190  \n2                -9.089155  \n3                36.842105  \n4               -12.236745  \n5                 4.321175  \n6                -9.659091  \n7                 7.817460  \n8                -1.537571  \n9               -14.637446  \n10               35.000000  \n11               18.636364  \n12               -7.741935  \n13               -0.118012  \n14                4.960664  \n15                2.532468  \n16                7.008929  \n17                9.998474  \n18               -2.803030  \n19              -11.173274  \n20              -12.993233  \n21              -15.837507  \n22               -8.486483  \n23               39.780220  \n24               -4.427664  \n25               50.000000  \n26               55.208333  \n27                1.041667  \n28               23.541667  \n29               -3.758394  \n30               18.700397  \n31              -19.185690  \n32                5.121997  \n33                     inf  \n34              -13.983037  \n35                8.686805  \n36               -1.111111  \n37               -6.975156  \n38               49.196429  \n39                4.391724  \n40              146.875000  \n41               -6.933685  \n42              -13.584471  \n43               -9.662641  \n44               79.166667  \n45               -9.500393  \n46               -6.715888  \n47                5.416195  \n48               40.000000  \n49              -11.805556  \n50                     inf  \n\n\n\n# Avoid division by zero when calculating percentage change\npivoted['AI_Growth_Pct'] = (\n    pivoted.groupby('STATE_NAME')['AI-Impacted']\n    .pct_change()\n    .replace([np.inf, -np.inf], np.nan)\n    * 100\n)\n\npivoted['Non_AI_Growth_Pct'] = (\n    pivoted.groupby('STATE_NAME')['Non-AI-Impacted']\n    .pct_change()\n    .replace([np.inf, -np.inf], np.nan)\n    * 100\n)\n\n\n\n\n\n# Drop rows where either value is still NaN (clean rows only)\npivoted.dropna(subset=['AI_Growth_Pct', 'Non_AI_Growth_Pct'], inplace=True)\n\n\n\navg_growth = (\n    pivoted.groupby('STATE_NAME')[['AI_Growth_Pct', 'Non_AI_Growth_Pct']]\n    .mean()\n    .reset_index()\n    .rename(columns={\n        'AI_Growth_Pct': 'Avg_AI_Job_Growth',\n        'Non_AI_Growth_Pct': 'Avg_Non_AI_Job_Growth'\n    })\n)\n\n\n\n\n\n# Top 10 states for AI job growth\ntop_ai = avg_growth.sort_values(by='Avg_AI_Job_Growth', ascending=False).head(10)\nprint(\"🔹 Top 10 States for AI Job Growth:\")\nprint(top_ai)\n\n# Top 10 states for Non-AI job growth\ntop_non_ai = avg_growth.sort_values(by='Avg_Non_AI_Job_Growth', ascending=False).head(10)\nprint(\"\\n🔹 Top 10 States for Non-AI Job Growth:\")\nprint(top_non_ai)\n\n🔹 Top 10 States for AI Job Growth:\nAI_IMPACTED    STATE_NAME  Avg_AI_Job_Growth  Avg_Non_AI_Job_Growth\n40           South Dakota          29.133065             -18.750000\n43                   Utah          26.428571             -34.893048\n35               Oklahoma          13.716049              41.245791\n30             New Mexico          10.673077              15.178571\n2                 Arizona           8.845947             -13.677419\n25                Montana           7.692308             300.000000\n44                Vermont           6.586022              75.000000\n5                Colorado           5.324124              -3.195489\n0                 Alabama           1.825137              31.250000\n6             Connecticut           0.980392               0.000000\n\n🔹 Top 10 States for Non-AI Job Growth:\nAI_IMPACTED     STATE_NAME  Avg_AI_Job_Growth  Avg_Non_AI_Job_Growth\n25                 Montana           7.692308             300.000000\n1                   Alaska         -18.633952             116.666667\n44                 Vermont           6.586022              75.000000\n48           West Virginia         -51.612903              60.000000\n28           New Hampshire         -12.554113              49.166667\n35                Oklahoma          13.716049              41.245791\n11                   Idaho         -27.073820              37.272727\n14                    Iowa         -12.772010              31.250000\n0                  Alabama           1.825137              31.250000\n10                  Hawaii          -2.547022              25.000000\n\n\n\nimport plotly.express as px\n\n# AI job growth plot\nfig_ai = px.bar(\n    top_ai,\n    x='STATE_NAME',\n    y='Avg_AI_Job_Growth',\n    title='Top 10 States by Average AI Job Growth',\n    labels={'STATE_NAME': 'State', 'Avg_AI_Job_Growth': 'Avg % AI Job Growth'},\n    text='Avg_AI_Job_Growth'\n)\nfig_ai.update_traces(texttemplate='%{text:.2f}%', textposition='outside')\nfig_ai.update_layout(yaxis_title='Average % Growth', xaxis_title='State')\nfig_ai.show()\n\n# Non-AI job growth plot\nfig_non_ai = px.bar(\n    top_non_ai,\n    x='STATE_NAME',\n    y='Avg_Non_AI_Job_Growth',\n    title='Top 10 States by Average Non-AI Job Growth',\n    labels={'STATE_NAME': 'State', 'Avg_Non_AI_Job_Growth': 'Avg % Non-AI Job Growth'},\n    text='Avg_Non_AI_Job_Growth'\n)\nfig_non_ai.update_traces(texttemplate='%{text:.2f}%', textposition='outside')\nfig_non_ai.update_layout(yaxis_title='Average % Growth', xaxis_title='State')\nfig_non_ai.show()\n\n\n                                                    \n\n\n                                                    \n\n\n\ndf['AVERAGE_SALARY'] = df[['SALARY_FROM', 'SALARY_TO']].mean(axis=1)\n\n\n---------------------------------------------------------------------------\nKeyError                                  Traceback (most recent call last)\nCell In[95], line 1\n----&gt; 1 df['AVERAGE_SALARY'] = df[['SALARY_FROM', 'SALARY_TO']].mean(axis=1)\n\nFile ~/metad688-job-market-analysis-for-summer-2025-group2/.venv/lib/python3.12/site-packages/pandas/core/frame.py:4108, in DataFrame.__getitem__(self, key)\n   4106     if is_iterator(key):\n   4107         key = list(key)\n-&gt; 4108     indexer = self.columns._get_indexer_strict(key, \"columns\")[1]\n   4110 # take() does not accept boolean indexers\n   4111 if getattr(indexer, \"dtype\", None) == bool:\n\nFile ~/metad688-job-market-analysis-for-summer-2025-group2/.venv/lib/python3.12/site-packages/pandas/core/indexes/base.py:6200, in Index._get_indexer_strict(self, key, axis_name)\n   6197 else:\n   6198     keyarr, indexer, new_indexer = self._reindex_non_unique(keyarr)\n-&gt; 6200 self._raise_if_missing(keyarr, indexer, axis_name)\n   6202 keyarr = self.take(indexer)\n   6203 if isinstance(key, Index):\n   6204     # GH 42790 - Preserve name from an Index\n\nFile ~/metad688-job-market-analysis-for-summer-2025-group2/.venv/lib/python3.12/site-packages/pandas/core/indexes/base.py:6249, in Index._raise_if_missing(self, key, indexer, axis_name)\n   6247 if nmissing:\n   6248     if nmissing == len(indexer):\n-&gt; 6249         raise KeyError(f\"None of [{key}] are in the [{axis_name}]\")\n   6251     not_found = list(ensure_index(key)[missing_mask.nonzero()[0]].unique())\n   6252     raise KeyError(f\"{not_found} not in index\")\n\nKeyError: \"None of [Index(['SALARY_FROM', 'SALARY_TO'], dtype='object')] are in the [columns]\"\n\n\n\n\navg_salary_by_state_type = (\n    df.groupby(['STATE_NAME', 'AI_IMPACTED'])['AVERAGE_SALARY']\n    .mean()\n    .reset_index()\n)\n\n\n\n---------------------------------------------------------------------------\nKeyError                                  Traceback (most recent call last)\nCell In[92], line 2\n      1 avg_salary_by_state_type = (\n----&gt; 2     df.groupby(['STATE_NAME', 'AI_IMPACTED'])['AVERAGE_SALARY']\n      3     .mean()\n      4     .reset_index()\n      5 )\n\nFile ~/metad688-job-market-analysis-for-summer-2025-group2/.venv/lib/python3.12/site-packages/pandas/core/groupby/generic.py:1951, in DataFrameGroupBy.__getitem__(self, key)\n   1944 if isinstance(key, tuple) and len(key) &gt; 1:\n   1945     # if len == 1, then it becomes a SeriesGroupBy and this is actually\n   1946     # valid syntax, so don't raise\n   1947     raise ValueError(\n   1948         \"Cannot subset columns with a tuple with more than one element. \"\n   1949         \"Use a list instead.\"\n   1950     )\n-&gt; 1951 return super().__getitem__(key)\n\nFile ~/metad688-job-market-analysis-for-summer-2025-group2/.venv/lib/python3.12/site-packages/pandas/core/base.py:244, in SelectionMixin.__getitem__(self, key)\n    242 else:\n    243     if key not in self.obj:\n--&gt; 244         raise KeyError(f\"Column not found: {key}\")\n    245     ndim = self.obj[key].ndim\n    246     return self._gotitem(key, ndim=ndim)\n\nKeyError: 'Column not found: AVERAGE_SALARY'\n\n\n\n\nimport numpy as np\n\n# Step 1: Replace infinite values (result of division by zero) with NaN\npivoted.replace([np.inf, -np.inf], np.nan, inplace=True)\n\n# Step 2: Drop rows with missing percentage growth values\npivoted.dropna(subset=['AI_Growth_Pct', 'Non_AI_Growth_Pct'], inplace=True)\n\n# Step 3: Group by state and calculate average percent growth\navg_growth = pivoted.groupby('STATE_NAME')[['AI_Growth_Pct', 'Non_AI_Growth_Pct']].mean().reset_index()\n\n# Step 4: Sort states by AI and Non-AI growth\nranked = avg_growth.sort_values(by=['AI_Growth_Pct', 'Non_AI_Growth_Pct'], ascending=False)\n\n# Step 5: Display top states for AI and Non-AI job growth\nfrom IPython.display import display\nprint(\"Top states by AI job growth:\")\ndisplay(ranked[['STATE_NAME', 'AI_Growth_Pct']].head(10))\n\nprint(\"\\nTop states by Non-AI job growth:\")\ndisplay(ranked[['STATE_NAME', 'Non_AI_Growth_Pct']].sort_values(by='Non_AI_Growth_Pct', ascending=False).head(10))\n\nTop states by AI job growth:\n\n\n\n\n\n\n\n\nAI_IMPACTED\nSTATE_NAME\nAI_Growth_Pct\n\n\n\n\n50\nWyoming\n78.532609\n\n\n25\nMontana\n45.827710\n\n\n48\nWest Virginia\n32.985093\n\n\n40\nSouth Dakota\n12.755376\n\n\n36\nOregon\n1.779482\n\n\n16\nKentucky\n1.127738\n\n\n30\nNew Mexico\n0.865385\n\n\n43\nUtah\n0.158730\n\n\n20\nMassachusetts\n0.114257\n\n\n44\nVermont\n-0.238949\n\n\n\n\n\n\n\n\nTop states by Non-AI job growth:\n\n\n\n\n\n\n\n\nAI_IMPACTED\nSTATE_NAME\nNon_AI_Growth_Pct\n\n\n\n\n33\nNorth Dakota\n533.333333\n\n\n40\nSouth Dakota\n220.833333\n\n\n38\nRhode Island\n94.166667\n\n\n25\nMontana\n77.777778\n\n\n50\nWyoming\n75.000000\n\n\n3\nArkansas\n65.789474\n\n\n1\nAlaska\n53.968254\n\n\n48\nWest Virginia\n53.333333\n\n\n11\nIdaho\n47.070707\n\n\n30\nNew Mexico\n43.452381\n\n\n\n\n\n\n\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Step 9: Visualize\nplt.figure(figsize=(14, 6))\navg_growth[['AI_Growth', 'Non_AI_Growth']].head(10).plot(kind='bar')\nplt.title('Average Monthly Job Growth (Top 10 States) for AI vs. Non-AI Careers')\nplt.ylabel('Average Monthly Job Growth')\nplt.xticks(rotation=45)\nplt.tight_layout()\nplt.grid(True)\nplt.show()\n\n\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[4], line 6\n      4 # Step 9: Visualize\n      5 plt.figure(figsize=(14, 6))\n----&gt; 6 avg_growth[['AI_Growth', 'Non_AI_Growth']].head(10).plot(kind='bar')\n      7 plt.title('Average Monthly Job Growth (Top 10 States) for AI vs. Non-AI Careers')\n      8 plt.ylabel('Average Monthly Job Growth')\n\nNameError: name 'avg_growth' is not defined\n\n\n\n&lt;Figure size 1400x600 with 0 Axes&gt;\n\n\n\n# Filter for Boston, MA and Austin, TX\nselected_state = ['California', 'Florida', 'Massachusetts', 'Texas', 'New York']\nfiltered_df = df[df['STATE_NAME'].isin(selected_state)]\n\n# Further filter for NAICS_2022_6 = 518210 and show relevant columns\nfinal_df = filtered_df[filtered_df['LOT_SPECIALIZED_OCCUPATION_NAME'].str.contains('analyst', case=False, na=False)]\nfinal_df[['STATE_NAME', 'NAICS2_NAME', 'NAICS_2022_6', 'LOT_SPECIALIZED_OCCUPATION_NAME']].head(100)\n\n\n\n\n\n\n\n\nSTATE_NAME\nNAICS2_NAME\nNAICS_2022_6\nLOT_SPECIALIZED_OCCUPATION_NAME\n\n\n\n\n2\nTexas\nFinance and Insurance\n524291.0\nData Analyst\n\n\n4\nCalifornia\nUnclassified Industry\n999999.0\nOracle Consultant / Analyst\n\n\n9\nNew York\nProfessional, Scientific, and Technical Services\n541511.0\nData Analyst\n\n\n10\nCalifornia\nWholesale Trade\n423830.0\nData Analyst\n\n\n15\nMassachusetts\nEducational Services\n611310.0\nData Analyst\n\n\n...\n...\n...\n...\n...\n\n\n294\nFlorida\nEducational Services\n611310.0\nSAP Analyst / Admin\n\n\n295\nCalifornia\nFinance and Insurance\n524114.0\nData Analyst\n\n\n296\nNew York\nUnclassified Industry\n999999.0\nGeneral ERP Analyst / Consultant\n\n\n297\nTexas\nProfessional, Scientific, and Technical Services\n541611.0\nSAP Analyst / Admin\n\n\n299\nTexas\nProfessional, Scientific, and Technical Services\n541511.0\nGeneral ERP Analyst / Consultant\n\n\n\n\n100 rows × 4 columns\n\n\n\n\n# Filter for Boston, MA and Austin, TX\nselected_state = ['California', 'Florida', 'Massachusetts', 'Texas', 'New York']\nfiltered_df = df[df['STATE_NAME'].isin(selected_state)]\n\n\n# Further filter for NAICS_2022_6 = 518210 and show relevant columns\nfinal_df = filtered_df[filtered_df['LOT_SPECIALIZED_OCCUPATION_NAME'].str.contains('analyst', case=False, na=False)]\nfinal_df[['STATE_NAME', 'NAICS2_NAME', 'NAICS_2022_6', 'LOT_SPECIALIZED_OCCUPATION_NAME']].head(100)\n\n\n\n\n\n\n\n\nSTATE_NAME\nNAICS2_NAME\nNAICS_2022_6\nLOT_SPECIALIZED_OCCUPATION_NAME\n\n\n\n\n2\nTexas\nFinance and Insurance\n524291.0\nData Analyst\n\n\n4\nCalifornia\nUnclassified Industry\n999999.0\nOracle Consultant / Analyst\n\n\n9\nNew York\nProfessional, Scientific, and Technical Services\n541511.0\nData Analyst\n\n\n10\nCalifornia\nWholesale Trade\n423830.0\nData Analyst\n\n\n15\nMassachusetts\nEducational Services\n611310.0\nData Analyst\n\n\n...\n...\n...\n...\n...\n\n\n294\nFlorida\nEducational Services\n611310.0\nSAP Analyst / Admin\n\n\n295\nCalifornia\nFinance and Insurance\n524114.0\nData Analyst\n\n\n296\nNew York\nUnclassified Industry\n999999.0\nGeneral ERP Analyst / Consultant\n\n\n297\nTexas\nProfessional, Scientific, and Technical Services\n541611.0\nSAP Analyst / Admin\n\n\n299\nTexas\nProfessional, Scientific, and Technical Services\n541511.0\nGeneral ERP Analyst / Consultant\n\n\n\n\n100 rows × 4 columns\n\n\n\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Group by STATE_NAME and count jobs for NAICS_2022_6 = 518210\nstate_counts_jobs = final_df.groupby('STATE_NAME').size().reset_index(name='job_count')\n\n# Sort state_counts_jobs from greatest to least by job_count\nstate_counts_jobs_sorted = state_counts_jobs.sort_values(by='job_count', ascending=False)\n\n# Plot column chart\nplt.figure(figsize=(8, 5))\ncolors = plt.cm.coolwarm(np.linspace(0, 1, len(state_counts_jobs_sorted)))\nplt.bar(state_counts_jobs_sorted['STATE_NAME'], state_counts_jobs_sorted['job_count'], color=colors)\nplt.xlabel('State')\nplt.ylabel('Number of Jobs')\nplt.title('Tech Jobs by State (Job Title Contains \"Analyst\")')\nplt.xticks(rotation=45)\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Geographic Analysis Group 2",
    "section": "",
    "text": "Artificial intelligence (AI) is a technology that allows computers and machines to mimic human abilities such as learning, understanding, solving problems, making decisions, being creative, and operating independently (Stryker, 2024). Over the next several years, generative AI will become the main focus of AI researchers and enthusiasts. Generative AI is a type of technology that can produce original text, images, and videos. With the rising popularity of generative AI, many companies are faced with the question of how to walk the line between technological advancements and ethical responsibility. Advocates of AI claim that when implemented properly, AI can boost productivity, accelerate product development, and improve business decision-making. In 2024, the International Monetary Fund estimated that 40% of jobs around the world will be affected by AI. Tech experts hypothesize that industries and sectors such as cybersecurity, financial services, and manufacturing (Expert Panel, 2021) are likely to be affected. On the other hand, some argue that while job displacement is inevitable, AI will also create new jobs. According to Lee, Samanta, and Lee (2024), AI will not eliminate jobs but instead will reshape career structures. Even so, there are still job types that can be at risk of being replaced. An example of a high-risk job would be one that involves repetition and predictable tasks, such as telemarketing and a customer support specialist. On the other hand, the more resilient jobs are those that require emotional intelligence or creative problem-solving. Some examples of these careers are teachers, writers, and employees with skilled trades like plumbers. Another important aspect to consider is that there will be some jobs where AI is used in conjunction with their regular responsibilities; an example of this is teachers. Teachers may use AI to grade papers, but they still will need to perform their regular tasks, like lecturing and mentoring students. Overall, Lee, Samanta, and Lee (2024) conclude that the rise of AI has a twofold effect: potential job displacement and the creation of new opportunities.\nThe double-edged effect appears to be the sentiment for Ito (2025), where she looks into the impact of job postings since OpenAI’s launch in 2022. Ito mentioned that she believed it would take a couple of years to truly see the impact of AI on the job market, but when evaluating in 2025, she found that AI’s revolution may have already begun. To confirm her hypothesis, Ito asked for Revelio Labs, an analytics provider, to see whether they can find jobs where AI has already replaced them. They first began by looking at current job descriptions to see which responsibilities AI could already replace or augment. Ultimately, they found that over the past three years, there was a 19% decline in jobs involving tasks that can be performed by AI. This drop was mainly due to companies hiring fewer roles that AI can handle. They also classified the jobs online into three categories: high exposure roles, low exposure roles, and those in between. Fundamentally, jobs with the highest exposure to AI started to disappear faster from online job postings. According to Revelio Labs, the jobs with the highest exposure are the ones that manage various technical functions like IT specialists, data engineers, and database administrators. On the other hand, the jobs with the lowest exposure are in-person roles like restaurant manager or mechanic. Essentially, there is data showing that AI has already disrupted the job market, but the article also emphasizes the point that its projection is still unknown. Experts cannot determine the sustainability of replacing humans with AI, especially when it comes to the quality of service that is produced.\nFrom a geographic perspective, McElheran et al. (2024) offers important insight into how AI adoption appears to be concentrated in select cities. This academic journal examines the 2018 Annual Business Survey to not only find out geographically where the highest AI implementation is, but also which firms are leading the charge. The data used for their analysis looks at 850,000 U.S. firms from early AI adoption to now. The journal classifies AI adoption by whether a firm has used at least one AI-related technology, including: machine learning, machine vision, automated guided vehicles, natural language processing, and voice recognition. Their findings showed that San Fransico was ranked as the top adopter of AI especially when it came to larger firms. Other notable cities with a high adoption rate were Nashville, TN; San Antonio, TX; and Tampa, FL. These findings suggest that early adopters of AI are large firms or high-growth startups in regions where there is more AI exposure.\n\n\nWith this in mind, our research will look at the rising trends within different industries in regards to AI. Specifically, we will compare the differences between careers impacted or related to AI vs careers that may not be as exposed. We will also examine which states have the most upcoming AI-related jobs by looking at the job postings dataset."
  },
  {
    "objectID": "index.html#purpose",
    "href": "index.html#purpose",
    "title": "Geographic Analysis Group 2",
    "section": "",
    "text": "With this in mind, our research will look at the rising trends within different industries in regards to AI. Specifically, we will compare the differences between careers impacted or related to AI vs careers that may not be as exposed. We will also examine which states have the most upcoming AI-related jobs by looking at the job postings dataset."
  },
  {
    "objectID": "ADAM geographic_analysis copy.html",
    "href": "ADAM geographic_analysis copy.html",
    "title": "Geographic Analysis",
    "section": "",
    "text": "North American Industry Classification System\n\nimport pandas as pd\nimport plotly.express as px\nimport plotly.io as pio\nimport numpy as np\n\nnp.random.seed(42)\n\npio.renderers.default = \"notebook\"\n\n\n## Listing Columns So We Can Reference them in Visuals\n\nimport pandas as pd\ndf = pd.read_csv(\"./data/lightcast_job_postings.csv\")\ndf.head()\n\n/tmp/ipykernel_2111/736325668.py:4: DtypeWarning:\n\nColumns (19,30) have mixed types. Specify dtype option on import or set low_memory=False.\n\n\n\n\n\n\n\n\n\n\nID\nLAST_UPDATED_DATE\nLAST_UPDATED_TIMESTAMP\nDUPLICATES\nPOSTED\nEXPIRED\nDURATION\nSOURCE_TYPES\nSOURCES\nURL\n...\nNAICS_2022_2\nNAICS_2022_2_NAME\nNAICS_2022_3\nNAICS_2022_3_NAME\nNAICS_2022_4\nNAICS_2022_4_NAME\nNAICS_2022_5\nNAICS_2022_5_NAME\nNAICS_2022_6\nNAICS_2022_6_NAME\n\n\n\n\n0\n1f57d95acf4dc67ed2819eb12f049f6a5c11782c\n9/6/2024\n2024-09-06 20:32:57.352 Z\n0.0\n6/2/2024\n6/8/2024\n6.0\n[\\n \"Company\"\\n]\n[\\n \"brassring.com\"\\n]\n[\\n \"https://sjobs.brassring.com/TGnewUI/Sear...\n...\n44.0\nRetail Trade\n441.0\nMotor Vehicle and Parts Dealers\n4413.0\nAutomotive Parts, Accessories, and Tire Retailers\n44133.0\nAutomotive Parts and Accessories Retailers\n441330.0\nAutomotive Parts and Accessories Retailers\n\n\n1\n0cb072af26757b6c4ea9464472a50a443af681ac\n8/2/2024\n2024-08-02 17:08:58.838 Z\n0.0\n6/2/2024\n8/1/2024\nNaN\n[\\n \"Job Board\"\\n]\n[\\n \"maine.gov\"\\n]\n[\\n \"https://joblink.maine.gov/jobs/1085740\"\\n]\n...\n56.0\nAdministrative and Support and Waste Managemen...\n561.0\nAdministrative and Support Services\n5613.0\nEmployment Services\n56132.0\nTemporary Help Services\n561320.0\nTemporary Help Services\n\n\n2\n85318b12b3331fa490d32ad014379df01855c557\n9/6/2024\n2024-09-06 20:32:57.352 Z\n1.0\n6/2/2024\n7/7/2024\n35.0\n[\\n \"Job Board\"\\n]\n[\\n \"dejobs.org\"\\n]\n[\\n \"https://dejobs.org/dallas-tx/data-analys...\n...\n52.0\nFinance and Insurance\n524.0\nInsurance Carriers and Related Activities\n5242.0\nAgencies, Brokerages, and Other Insurance Rela...\n52429.0\nOther Insurance Related Activities\n524291.0\nClaims Adjusting\n\n\n3\n1b5c3941e54a1889ef4f8ae55b401a550708a310\n9/6/2024\n2024-09-06 20:32:57.352 Z\n1.0\n6/2/2024\n7/20/2024\n48.0\n[\\n \"Job Board\"\\n]\n[\\n \"disabledperson.com\",\\n \"dejobs.org\"\\n]\n[\\n \"https://www.disabledperson.com/jobs/5948...\n...\n52.0\nFinance and Insurance\n522.0\nCredit Intermediation and Related Activities\n5221.0\nDepository Credit Intermediation\n52211.0\nCommercial Banking\n522110.0\nCommercial Banking\n\n\n4\ncb5ca25f02bdf25c13edfede7931508bfd9e858f\n6/19/2024\n2024-06-19 07:00:00.000 Z\n0.0\n6/2/2024\n6/17/2024\n15.0\n[\\n \"FreeJobBoard\"\\n]\n[\\n \"craigslist.org\"\\n]\n[\\n \"https://modesto.craigslist.org/sls/77475...\n...\n99.0\nUnclassified Industry\n999.0\nUnclassified Industry\n9999.0\nUnclassified Industry\n99999.0\nUnclassified Industry\n999999.0\nUnclassified Industry\n\n\n\n\n5 rows × 131 columns\n\n\n\n\n# Filter for Boston, MA and Austin, TX\nselected_state = ['California', 'Florida', 'Massachusetts', 'Texas', 'New York']\nfiltered_df = df[df['STATE_NAME'].isin(selected_state)]\n\n# Further filter for NAICS_2022_6 = 518210 and show relevant columns\nfinal_df = filtered_df[filtered_df['LOT_SPECIALIZED_OCCUPATION_NAME'].str.contains('analyst', case=False, na=False)]\nfinal_df[['STATE_NAME', 'NAICS2_NAME', 'NAICS_2022_6', 'LOT_SPECIALIZED_OCCUPATION_NAME']].head(100)\n\n\n\n\n\n\n\n\nSTATE_NAME\nNAICS2_NAME\nNAICS_2022_6\nLOT_SPECIALIZED_OCCUPATION_NAME\n\n\n\n\n2\nTexas\nFinance and Insurance\n524291.0\nData Analyst\n\n\n4\nCalifornia\nUnclassified Industry\n999999.0\nOracle Consultant / Analyst\n\n\n9\nNew York\nProfessional, Scientific, and Technical Services\n541511.0\nData Analyst\n\n\n10\nCalifornia\nWholesale Trade\n423830.0\nData Analyst\n\n\n15\nMassachusetts\nEducational Services\n611310.0\nData Analyst\n\n\n...\n...\n...\n...\n...\n\n\n294\nFlorida\nEducational Services\n611310.0\nSAP Analyst / Admin\n\n\n295\nCalifornia\nFinance and Insurance\n524114.0\nData Analyst\n\n\n296\nNew York\nUnclassified Industry\n999999.0\nGeneral ERP Analyst / Consultant\n\n\n297\nTexas\nProfessional, Scientific, and Technical Services\n541611.0\nSAP Analyst / Admin\n\n\n299\nTexas\nProfessional, Scientific, and Technical Services\n541511.0\nGeneral ERP Analyst / Consultant\n\n\n\n\n100 rows × 4 columns\n\n\n\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Group by STATE_NAME and count jobs for NAICS_2022_6 = 518210\nstate_counts_jobs = final_df.groupby('STATE_NAME').size().reset_index(name='job_count')\n\n# Sort state_counts_jobs from greatest to least by job_count\nstate_counts_jobs_sorted = state_counts_jobs.sort_values(by='job_count', ascending=False)\n\n# Plot column chart\nplt.figure(figsize=(8, 5))\ncolors = plt.cm.coolwarm(np.linspace(0, 1, len(state_counts_jobs_sorted)))\nplt.bar(state_counts_jobs_sorted['STATE_NAME'], state_counts_jobs_sorted['job_count'], color=colors)\nplt.xlabel('State')\nplt.ylabel('Number of Jobs')\nplt.title('Tech Jobs by State (Job Title Contains \"Analyst\")')\nplt.xticks(rotation=45)\nplt.tight_layout()\nplt.savefig('figures/states_analyst_jobs.png', dpi=300, bbox_inches='tight')\nplt.show()\n\n\n\n\n\n\n\n\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Group by STATE_NAME and count jobs for analysts\ncity_counts_jobs = final_df.groupby('CITY_NAME').size().reset_index(name='job_count')\n\n# Sort state_counts_jobs from greatest to least by job_count and get top 10\ncity_counts_jobs_sorted = city_counts_jobs.sort_values(by='job_count', ascending=False).head(10)\n\n# Plot column chart\nplt.figure(figsize=(10, 6))\ncolors = plt.cm.coolwarm(np.linspace(0, 1, len(city_counts_jobs_sorted)))\nplt.bar(city_counts_jobs_sorted['CITY_NAME'], city_counts_jobs_sorted['job_count'], color=colors)\nplt.xlabel('City')\nplt.ylabel('Number of Jobs')\nplt.title('Top 10 Cities - Tech Jobs (Job Title Contains \"Analyst\")')\nplt.xticks(rotation=45)\nplt.tight_layout()\n\n# Save the figure to the figures folder\nplt.savefig('figures/top_10_cities_analyst_jobs.png', dpi=300, bbox_inches='tight')\n\nplt.show()\n\n\n\n\n\n\n\n\n\nimport plotly.express as px\nimport plotly.io as pio\n\n# Create nationwide data - remove state filtering to include all states\ntry:\n    # Use the original df (before state filtering) to get all states\n    all_states_df = df[df['LOT_SPECIALIZED_OCCUPATION_NAME'].str.contains('analyst', case=False, na=False)]\nexcept NameError:\n    # If df not available, load it fresh\n    import pandas as pd\n    df_temp = pd.read_csv(\"./data/lightcast_job_postings.csv\")\n    all_states_df = df_temp[df_temp['LOT_SPECIALIZED_OCCUPATION_NAME'].str.contains('analyst', case=False, na=False)]\n\n# Group by all states and count jobs\nall_state_counts = all_states_df.groupby('STATE_NAME').size().reset_index(name='job_count')\nall_state_counts_sorted = all_state_counts.sort_values(by='job_count', ascending=False)\n\nprint(\"Top 10 states with most analyst jobs:\")\nprint(all_state_counts_sorted.head(10))\nprint(f\"\\nTotal states with analyst jobs: {len(all_state_counts_sorted)}\")\n\n# Comprehensive state abbreviation mapping\nstate_abbrev_map = {\n    'Alabama': 'AL', 'Alaska': 'AK', 'Arizona': 'AZ', 'Arkansas': 'AR', 'California': 'CA',\n    'Colorado': 'CO', 'Connecticut': 'CT', 'Delaware': 'DE', 'Florida': 'FL', 'Georgia': 'GA',\n    'Hawaii': 'HI', 'Idaho': 'ID', 'Illinois': 'IL', 'Indiana': 'IN', 'Iowa': 'IA',\n    'Kansas': 'KS', 'Kentucky': 'KY', 'Louisiana': 'LA', 'Maine': 'ME', 'Maryland': 'MD',\n    'Massachusetts': 'MA', 'Michigan': 'MI', 'Minnesota': 'MN', 'Mississippi': 'MS', 'Missouri': 'MO',\n    'Montana': 'MT', 'Nebraska': 'NE', 'Nevada': 'NV', 'New Hampshire': 'NH', 'New Jersey': 'NJ',\n    'New Mexico': 'NM', 'New York': 'NY', 'North Carolina': 'NC', 'North Dakota': 'ND', 'Ohio': 'OH',\n    'Oklahoma': 'OK', 'Oregon': 'OR', 'Pennsylvania': 'PA', 'Rhode Island': 'RI', 'South Carolina': 'SC',\n    'South Dakota': 'SD', 'Tennessee': 'TN', 'Texas': 'TX', 'Utah': 'UT', 'Vermont': 'VT',\n    'Virginia': 'VA', 'Washington': 'WA', 'West Virginia': 'WV', 'Wisconsin': 'WI', 'Wyoming': 'WY',\n    'District of Columbia': 'DC'\n}\n\n# Add state abbreviations to the data\nall_state_counts_sorted['state_abbrev'] = all_state_counts_sorted['STATE_NAME'].map(state_abbrev_map)\n\n# Filter out any states that couldn't be mapped (in case of data issues)\nmapped_states = all_state_counts_sorted.dropna(subset=['state_abbrev'])\n\nprint(f\"\\nStates successfully mapped: {len(mapped_states)}\")\nif len(mapped_states) &lt; len(all_state_counts_sorted):\n    unmapped = all_state_counts_sorted[all_state_counts_sorted['state_abbrev'].isna()]\n    print(\"Unmapped states:\")\n    print(unmapped['STATE_NAME'].tolist())\n\n# Create a choropleth map showing job counts for all states\nfig = px.choropleth(\n    mapped_states,\n    locations='state_abbrev',\n    color='job_count',\n    locationmode='USA-states',\n    color_continuous_scale='Greens',\n    labels={'job_count': 'Number of Jobs', 'STATE_NAME': 'State'},\n    hover_name='STATE_NAME',\n    hover_data={'state_abbrev': False, 'job_count': True}\n)\n\n# Update layout with no title to maximize map space\nfig.update_layout(\n    geo_scope='usa',\n    width=1000,\n    height=700,\n    margin=dict(t=5, b=5, l=5, r=5),  # Minimal margins on all sides\n    geo=dict(\n        projection_type='albers usa',\n        showlakes=True,\n        lakecolor='rgb(255, 255, 255)',\n        bgcolor='rgba(0,0,0,0)'\n    )\n)\n\n# Show the interactive map\nfig.show()\n\nTop 10 states with most analyst jobs:\n        STATE_NAME  job_count\n42           Texas       7084\n4       California       6501\n8          Florida       3206\n31        New York       3056\n12        Illinois       3045\n45        Virginia       2989\n32  North Carolina       2423\n34            Ohio       2403\n9          Georgia       2363\n29      New Jersey       2289\n\nTotal states with analyst jobs: 51\n\nStates successfully mapped: 50\nUnmapped states:\n['Washington, D.C. (District of Columbia)']\n\n\n        \n        \n        \n\n\n                                                    \n\n\n\n\nInteractive map showing the distribution of analyst jobs across all US states.\n\n# filter df for NAICS_2022_2 is 44 and is 51\n\n# df_41 = df[df['NAICS_2022_2'].isin(['44'])]\n# \n# df_41.head()\n\n\nselected_naics = [11, 21, 22]\nfiltered_df = df[df['NAICS_2022_2'].isin(selected_naics)]\n\n# Further filter for NAICS_2022_6 = 518210 and show relevant columns\n# final_df = filtered_df[filtered_df['NAICS_2022_2'].str.contains('analyst', case=False, na=False)]\nfiltered_df[['STATE_NAME', 'NAICS_2022_2', 'NAICS_2022_2_NAME', 'LOT_SPECIALIZED_OCCUPATION_NAME']].head(100)\n\n\n\n\n\n\n\n\nSTATE_NAME\nNAICS_2022_2\nNAICS_2022_2_NAME\nLOT_SPECIALIZED_OCCUPATION_NAME\n\n\n\n\n376\nNorth Carolina\n21.0\nMining, Quarrying, and Oil and Gas Extraction\nData Analyst\n\n\n394\nNorth Carolina\n22.0\nUtilities\nGeneral ERP Analyst / Consultant\n\n\n502\nCalifornia\n22.0\nUtilities\nBusiness Analyst (General)\n\n\n525\nNebraska\n22.0\nUtilities\nBusiness Analyst (General)\n\n\n632\nMassachusetts\n22.0\nUtilities\nBusiness Analyst (General)\n\n\n...\n...\n...\n...\n...\n\n\n8531\nMichigan\n21.0\nMining, Quarrying, and Oil and Gas Extraction\nData Analyst\n\n\n8553\nTexas\n22.0\nUtilities\nEnterprise Architect\n\n\n8682\nFlorida\n11.0\nAgriculture, Forestry, Fishing and Hunting\nGeneral ERP Analyst / Consultant\n\n\n8698\nColorado\n22.0\nUtilities\nEnterprise Architect\n\n\n8702\nOregon\n22.0\nUtilities\nEnterprise Architect\n\n\n\n\n100 rows × 4 columns"
  },
  {
    "objectID": "ADAM geographic_analysis copy.html#tech-jobs-nationwide-job-title-contains-analyst",
    "href": "ADAM geographic_analysis copy.html#tech-jobs-nationwide-job-title-contains-analyst",
    "title": "Geographic Analysis",
    "section": "",
    "text": "Interactive map showing the distribution of analyst jobs across all US states.\n\n# filter df for NAICS_2022_2 is 44 and is 51\n\n# df_41 = df[df['NAICS_2022_2'].isin(['44'])]\n# \n# df_41.head()\n\n\nselected_naics = [11, 21, 22]\nfiltered_df = df[df['NAICS_2022_2'].isin(selected_naics)]\n\n# Further filter for NAICS_2022_6 = 518210 and show relevant columns\n# final_df = filtered_df[filtered_df['NAICS_2022_2'].str.contains('analyst', case=False, na=False)]\nfiltered_df[['STATE_NAME', 'NAICS_2022_2', 'NAICS_2022_2_NAME', 'LOT_SPECIALIZED_OCCUPATION_NAME']].head(100)\n\n\n\n\n\n\n\n\nSTATE_NAME\nNAICS_2022_2\nNAICS_2022_2_NAME\nLOT_SPECIALIZED_OCCUPATION_NAME\n\n\n\n\n376\nNorth Carolina\n21.0\nMining, Quarrying, and Oil and Gas Extraction\nData Analyst\n\n\n394\nNorth Carolina\n22.0\nUtilities\nGeneral ERP Analyst / Consultant\n\n\n502\nCalifornia\n22.0\nUtilities\nBusiness Analyst (General)\n\n\n525\nNebraska\n22.0\nUtilities\nBusiness Analyst (General)\n\n\n632\nMassachusetts\n22.0\nUtilities\nBusiness Analyst (General)\n\n\n...\n...\n...\n...\n...\n\n\n8531\nMichigan\n21.0\nMining, Quarrying, and Oil and Gas Extraction\nData Analyst\n\n\n8553\nTexas\n22.0\nUtilities\nEnterprise Architect\n\n\n8682\nFlorida\n11.0\nAgriculture, Forestry, Fishing and Hunting\nGeneral ERP Analyst / Consultant\n\n\n8698\nColorado\n22.0\nUtilities\nEnterprise Architect\n\n\n8702\nOregon\n22.0\nUtilities\nEnterprise Architect\n\n\n\n\n100 rows × 4 columns"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Hello\nAbout this site"
  },
  {
    "objectID": "market_trends.html",
    "href": "market_trends.html",
    "title": "Market Trends",
    "section": "",
    "text": "Introduction\nOur group has decided to evaluate the distribution of jobs related to techonology across the United States. In order to do this, we used a count of any jobs containing the word “analyst” and categorized them by state. The results of this are shown below.\n\nAnalyst Job Distribution Across the United States\n\n\nAccording to the visual above, Texas and California are the two clear leaders in the total amount of jobs being offered that contain the word “analyst” in the title. Additionally, eastern states show a considerably greater amount of these jobs compared to western states.\n\nAnalyst Job Distribution Across Cities in the United States\n\n\n```"
  }
]